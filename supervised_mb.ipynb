{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f07c8493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "987367f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31e7555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For moving all img files from one root dir to another\n",
    "# source = \"Train\"\n",
    "# dest = \"Train1\"\n",
    "\n",
    "# label_flood_dir = os.path.join('Labeled','Flooded','image')\n",
    "# label_nonflood_dir = os.path.join('Labeled','Non-Flooded','image')\n",
    "\n",
    "# for dire in label_flood_dir,label_nonflood_dir:\n",
    "#     source_dir = os.path.join(source,dire)\n",
    "#     dest_dir = os.path.join(dest,dire)\n",
    "#     for file in os.listdir(source_dir):\n",
    "#         source_file = os.path.join(source_dir,file)\n",
    "#         dest_file = os.path.join(dest_dir,file)\n",
    "#         os.rename(source_file,dest_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7554149c",
   "metadata": {},
   "source": [
    "Should take around 3 minutes to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b807b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data from Memory\n",
      "Loaded!\n"
     ]
    }
   ],
   "source": [
    "h_dim = 1000\n",
    "v_dim = 750\n",
    "print(\"Loading Data from Memory\")\n",
    "\n",
    "root = \"Train\"\n",
    "label_flood_dir = os.path.join(root,'Labeled','Flooded','image')\n",
    "label_nonflood_dir = os.path.join(root,'Labeled','Non-Flooded','image')\n",
    "flooded_img = []\n",
    "nonflooded_img = []\n",
    "\n",
    "for file in os.listdir(label_flood_dir):\n",
    "    image = Image.open(os.path.join(label_flood_dir, file))\n",
    "    flooded_img.append(np.array(image.resize((h_dim,v_dim))))\n",
    "    \n",
    "for file in os.listdir(label_nonflood_dir):\n",
    "    image = Image.open(os.path.join(label_nonflood_dir, file))\n",
    "    nonflooded_img.append(np.array(image.resize((h_dim,v_dim))))\n",
    "print(\"Loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f26586fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flooded Image Shape: (750, 1000, 3)\n",
      "Non_Flooded Image Shape: (750, 1000, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(397, 750, 1000, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Flooded Image Shape: {}\".format(flooded_img[0].shape))\n",
    "print(\"Non_Flooded Image Shape: {}\".format(nonflooded_img[0].shape))\n",
    "\n",
    "data_img = np.vstack((np.array(flooded_img), np.array(nonflooded_img))) / 255.\n",
    "data_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3ee3dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Index: [  0   2   3   4   5   6   7   8   9  10  11  13  14  15  16  17  19  21\n",
      "  22  23  24  25  26  27  30  31  32  33  34  35  36  37  39  40  42  44\n",
      "  45  47  48  49  56  59  85  89 101 102 109 110 132 134 140 148 152 176\n",
      " 177 178 179 205 211 223 226 232 260 261 264 267 272 295 322 324 325 327\n",
      " 331 334 335 338 342 352 355 395]\n",
      "Testing Index: [  1  12  18  20  28  29  38  41  43  46  50  53  62  63  79 100 144 245\n",
      " 303 326 346 394]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "test = False\n",
    "\n",
    "#n is number images from each class (flooded or non flooded)\n",
    "if test == True:\n",
    "    n = 20\n",
    "    #train_idx = np.array([np.arange(7),np.arange(10,17)]).flatten()\n",
    "    #test_idx = np.array([np.arange(7,10),np.arange(17,20)]).flatten()\n",
    "else:\n",
    "    n = min(len(flooded_img),len(nonflooded_img))\n",
    "\n",
    "'''split data 50 50'''\n",
    "def train_test_split(n):\n",
    "    idxs = list(range(n))\n",
    "    s = int(np.floor(0.8*n)) # number of images for training\n",
    "    \n",
    "    train_idx = []\n",
    "    test_idx = []\n",
    "    \n",
    "    #index range to select from (flooded img range, non flooded image range)\n",
    "    for s_i,e_i in [(0,len(flooded_img)),(len(flooded_img),len(data_img))]:\n",
    "        \n",
    "        #print(s_i,e_i,n,s)\n",
    "        #get all poss indexes for set\n",
    "        s_idx = list(range(s_i,e_i))\n",
    "        random.shuffle(s_idx)\n",
    "        \n",
    "        train_idx.extend(s_idx[:s])      #first s images are for training\n",
    "        test_idx.extend(s_idx[s:n])      # next n-s images are for testing. \n",
    "        #print(len(train_idx))\n",
    "    \n",
    "    train_idx = np.array(train_idx)\n",
    "    test_idx = np.array(test_idx)\n",
    "    train_idx.sort()\n",
    "    test_idx.sort()\n",
    "    \n",
    "    train_labels = [1 if x<len(flooded_img) else 0 for x in train_idx]\n",
    "    test_labels = [1 if x<len(flooded_img) else 0 for x in test_idx]\n",
    "\n",
    "    print(\"Training Index: {}\".format(train_idx))\n",
    "    print(\"Testing Index: {}\".format(test_idx))\n",
    "    return train_idx, test_idx, train_labels, test_labels\n",
    "\n",
    "train_idx, test_idx, train_labels, test_labels = train_test_split(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f174344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutional layer\n",
    "# x the input \n",
    "# shape is dimension of input\n",
    "def conv_layer(x, shape):\n",
    "\n",
    "    weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "    bias = tf.Variable(tf.constant(0.05, shape=[shape[-1]]))\n",
    "\n",
    "    out = tf.nn.conv2d(input=x, filters=weights, strides=[1,1,1,1], padding='SAME')\n",
    "    out += bias\n",
    "    return out\n",
    "\n",
    "# pooling layer\n",
    "def max_pool(x, k=2):\n",
    "\n",
    "    out = tf.nn.max_pool(value=x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "    return out\n",
    "\n",
    "# fully connected layer\n",
    "def fully_connected_layer(x, shape):\n",
    "\n",
    "    weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "    bias = tf.Variable(tf.constant(0.05, shape=[shape[1]]))\n",
    "\n",
    "    out = tf.matmul(a=x, b=weights)\n",
    "    out += bias\n",
    "    return out\n",
    "\n",
    "# flatten layer\n",
    "def flatten_layer(x):\n",
    "    \n",
    "    size = x.get_shape()[1:4].num_elements()\n",
    "    out = tf.reshape(x, [-1,size])\n",
    "    return out, size\n",
    "\n",
    "# relu\n",
    "relu = lambda x: tf.nn.relu(features=x)\n",
    "\n",
    "# softmax\n",
    "softmax = lambda x: tf.nn.softmax(logits=x)\n",
    "\n",
    "# sigmoid\n",
    "sigmoid = lambda x: tf.nn.sigmoid(x)\n",
    "\n",
    "# batch norm\n",
    "batch_norm = lambda x: tf.layers.batch_normalization(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23470b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define CNN\n",
    "def toy_model(x):\n",
    "    \n",
    "    #shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "    def conv_block(x,in_channels,out_channels,kernel_h=5,kernel_w =5):\n",
    "        shape = [kernel_h,kernel_w,in_channels,out_channels]\n",
    "        x = conv_layer(x, shape)\n",
    "        x = relu(x)\n",
    "        x = batch_norm(x)\n",
    "        x = max_pool(x, k=2)\n",
    "        return x\n",
    "    \n",
    "    x = conv_block(x,3,16)\n",
    "    x = conv_block(x,16,16)\n",
    "    x = conv_block(x,16,32)\n",
    "    x = conv_block(x,32,32)\n",
    "    x = conv_block(x,32,64)\n",
    "    x = conv_block(x,64,64)\n",
    "    x = conv_block(x,64,1)\n",
    "    \n",
    "    # Six convolutional layers with max pool and ReLU\n",
    "#     shape0 = [5, 5, 3, 3]\n",
    "#     conv0 = conv_layer(x, shape0)\n",
    "#     conv0 = relu(conv0)\n",
    "#     conv0 = batch_norm(conv0)\n",
    "#     conv0 = max_pool(conv0, k=2)\n",
    "\n",
    "#     shape1 = [5, 5, 3, 3]\n",
    "#     conv1 = conv_layer(conv0, shape1)\n",
    "#     conv1 = relu(conv1)\n",
    "#     conv1 = batch_norm(conv1)\n",
    "#     conv1 = max_pool(conv1, k=2)\n",
    "\n",
    "#     shape2 = [5, 5, 3, 3]\n",
    "#     conv2 = conv_layer(conv1, shape2)\n",
    "#     conv2 = relu(conv2)\n",
    "#     conv2 = batch_norm(conv2)\n",
    "#     conv2 = max_pool(conv2, k=2)\n",
    "\n",
    "#     shape3 = [5, 5, 3, 1]\n",
    "#     conv3 = conv_layer(conv2, shape3)\n",
    "#     conv3 = relu(conv3)\n",
    "#     conv3 = batch_norm(conv3)\n",
    "#     conv3 = max_pool(conv3, k=2)\n",
    "\n",
    "#     shape4 = [5, 5, 1, 1]\n",
    "#     conv4 = conv_layer(conv3, shape4)\n",
    "#     conv4 = relu(conv4)\n",
    "#     conv4 = batch_norm(conv4)\n",
    "#     conv4 = max_pool(conv4, k=2)\n",
    "\n",
    "#     shape5 = [5, 5, 1, 1]\n",
    "#     conv5 = conv_layer(conv4, shape5)\n",
    "#     conv5 = relu(conv5)\n",
    "#     conv5 = batch_norm(conv5)\n",
    "#     conv5 = max_pool(conv5, k=2)\n",
    "\n",
    "    # flatten output and put through a fully connected layer\n",
    "    flat1, size1 = flatten_layer(x)\n",
    "    fc1 = fully_connected_layer(flat1, [size1, 64])\n",
    "    fc1 = relu(fc1)\n",
    "\n",
    "    fc2 = fully_connected_layer(fc1, [64, 1])\n",
    "\n",
    "    return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37a79a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sharpen(p):\n",
    "#     T = 0.5\n",
    "#     pred = p**(1./T)/(p**(1./T) + (1.-p)**(1./T))\n",
    "#     return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49b8f703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define inputs\n",
    "x = tf.placeholder(tf.float32, [None, v_dim, h_dim, 3])\n",
    "y = tf.placeholder(tf.float32, [None, 1])\n",
    "y_train_true = np.array(train_labels).reshape(-1,1)\n",
    "y_test_true = np.array(test_labels).reshape(-1,1)\n",
    "\n",
    "# run model with placeholder tensors\n",
    "pred = toy_model(x)\n",
    "\n",
    "# sharpen\n",
    "# pred = sharpen(pred)\n",
    "\n",
    "# define loss\n",
    "cross_entropy = tf.losses.sigmoid_cross_entropy(logits=pred, multi_class_labels=y)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# define accuracy\n",
    "pred_class = tf.round(sigmoid(pred))\n",
    "pred_correct = tf.equal(pred_class, tf.cast(y, tf.float32))\n",
    "accuracy = tf.reduce_mean(tf.cast(pred_correct, tf.float32))\n",
    "\n",
    "# define optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cost)\n",
    "\n",
    "# initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "training_iters = 500\n",
    "batch_size = 4 #len(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c10a870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Loss= 0.704715, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 1, Loss= 0.696570, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 2, Loss= 0.696089, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 3, Loss= 0.695875, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 4, Loss= 0.695711, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 5, Loss= 0.695576, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 6, Loss= 0.695459, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 7, Loss= 0.695358, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 8, Loss= 0.695270, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 9, Loss= 0.695193, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 10, Loss= 0.695124, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 11, Loss= 0.695063, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 12, Loss= 0.695009, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 13, Loss= 0.694959, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 14, Loss= 0.694914, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 15, Loss= 0.694874, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 16, Loss= 0.694837, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 17, Loss= 0.694802, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 18, Loss= 0.694771, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 19, Loss= 0.694742, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 20, Loss= 0.694716, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 21, Loss= 0.694694, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 22, Loss= 0.694697, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 23, Loss= 0.694880, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 24, Loss= 0.695863, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 25, Loss= 0.695512, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 26, Loss= 0.694581, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 27, Loss= 0.694523, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 28, Loss= 0.694513, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 29, Loss= 0.694495, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 30, Loss= 0.694480, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 31, Loss= 0.694465, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 32, Loss= 0.694450, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 33, Loss= 0.694436, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 34, Loss= 0.694422, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 35, Loss= 0.694408, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 36, Loss= 0.694395, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 37, Loss= 0.694382, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 38, Loss= 0.694369, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 39, Loss= 0.694357, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 40, Loss= 0.694344, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 41, Loss= 0.694332, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 42, Loss= 0.694321, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 43, Loss= 0.694309, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 44, Loss= 0.694297, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 45, Loss= 0.694286, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 46, Loss= 0.694275, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 47, Loss= 0.694264, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 48, Loss= 0.694254, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 49, Loss= 0.694243, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 50, Loss= 0.694233, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 51, Loss= 0.694222, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 52, Loss= 0.694212, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 53, Loss= 0.694203, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 54, Loss= 0.694193, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 55, Loss= 0.694183, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 56, Loss= 0.694174, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 57, Loss= 0.694165, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 58, Loss= 0.694155, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 59, Loss= 0.694147, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 60, Loss= 0.694138, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 61, Loss= 0.694129, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 62, Loss= 0.694121, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 63, Loss= 0.694112, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 64, Loss= 0.694104, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 65, Loss= 0.694096, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 66, Loss= 0.694088, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 67, Loss= 0.694080, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 68, Loss= 0.694072, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 69, Loss= 0.694065, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 70, Loss= 0.694057, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 71, Loss= 0.694050, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 72, Loss= 0.694043, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 73, Loss= 0.694036, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 74, Loss= 0.694029, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 75, Loss= 0.694022, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 76, Loss= 0.694015, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 77, Loss= 0.694008, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 78, Loss= 0.694002, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 79, Loss= 0.693995, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 80, Loss= 0.693989, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 81, Loss= 0.693985, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 82, Loss= 0.693959, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 83, Loss= 0.693994, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 84, Loss= 0.694346, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 85, Loss= 0.694851, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 86, Loss= 0.694399, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 87, Loss= 0.693958, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 88, Loss= 0.693910, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 89, Loss= 0.693905, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 90, Loss= 0.693899, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 91, Loss= 0.693895, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 92, Loss= 0.693890, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 93, Loss= 0.693885, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 94, Loss= 0.693881, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 95, Loss= 0.693877, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 96, Loss= 0.693872, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 97, Loss= 0.693868, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 98, Loss= 0.693864, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 99, Loss= 0.693859, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 100, Loss= 0.693855, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 101, Loss= 0.693851, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 102, Loss= 0.693847, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 103, Loss= 0.693843, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 104, Loss= 0.693838, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 105, Loss= 0.693834, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 106, Loss= 0.693830, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 107, Loss= 0.693826, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 108, Loss= 0.693822, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 109, Loss= 0.693819, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 110, Loss= 0.693815, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 111, Loss= 0.693811, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 112, Loss= 0.693807, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 113, Loss= 0.693803, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 114, Loss= 0.693800, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 115, Loss= 0.693796, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 116, Loss= 0.693792, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 117, Loss= 0.693788, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 118, Loss= 0.693785, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 119, Loss= 0.693781, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 120, Loss= 0.693778, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 121, Loss= 0.693774, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 122, Loss= 0.693771, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 123, Loss= 0.693767, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 124, Loss= 0.693764, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 125, Loss= 0.693760, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 126, Loss= 0.693757, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 127, Loss= 0.693754, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 128, Loss= 0.693751, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 129, Loss= 0.693747, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 130, Loss= 0.693744, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 131, Loss= 0.693741, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 132, Loss= 0.693738, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 133, Loss= 0.693734, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 134, Loss= 0.693731, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 135, Loss= 0.693728, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 136, Loss= 0.693725, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 137, Loss= 0.693722, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 138, Loss= 0.693719, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 139, Loss= 0.693716, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 140, Loss= 0.693713, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 141, Loss= 0.693710, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 142, Loss= 0.693708, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 143, Loss= 0.693705, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 144, Loss= 0.693702, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 145, Loss= 0.693699, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 146, Loss= 0.693696, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 147, Loss= 0.693694, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 148, Loss= 0.693691, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 149, Loss= 0.693688, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 150, Loss= 0.693686, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 151, Loss= 0.693683, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 152, Loss= 0.693680, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 153, Loss= 0.693678, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 154, Loss= 0.693675, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 155, Loss= 0.693673, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 156, Loss= 0.693670, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 157, Loss= 0.693668, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 158, Loss= 0.693666, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 159, Loss= 0.693663, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 160, Loss= 0.693661, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 161, Loss= 0.693659, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 162, Loss= 0.693656, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 163, Loss= 0.693654, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 164, Loss= 0.693652, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 165, Loss= 0.693650, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 166, Loss= 0.693647, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 167, Loss= 0.693645, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 168, Loss= 0.693643, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 169, Loss= 0.693641, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 170, Loss= 0.693639, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 171, Loss= 0.693637, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 172, Loss= 0.693635, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 173, Loss= 0.693633, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 174, Loss= 0.693631, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 175, Loss= 0.693629, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 176, Loss= 0.693627, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 177, Loss= 0.693625, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 178, Loss= 0.693624, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 179, Loss= 0.693622, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 180, Loss= 0.693620, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 181, Loss= 0.693618, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 182, Loss= 0.693616, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 183, Loss= 0.693615, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 184, Loss= 0.693613, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 185, Loss= 0.693611, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 186, Loss= 0.693610, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 187, Loss= 0.693608, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 188, Loss= 0.693606, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 189, Loss= 0.693605, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 190, Loss= 0.693603, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 191, Loss= 0.693602, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 192, Loss= 0.693600, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 193, Loss= 0.693599, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 194, Loss= 0.693597, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 195, Loss= 0.693596, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 196, Loss= 0.693594, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 197, Loss= 0.693593, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 198, Loss= 0.693591, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 199, Loss= 0.693590, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 200, Loss= 0.693588, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 201, Loss= 0.693587, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 202, Loss= 0.693586, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 203, Loss= 0.693584, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 204, Loss= 0.693583, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 205, Loss= 0.693582, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 206, Loss= 0.693581, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 207, Loss= 0.693580, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 208, Loss= 0.693580, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 209, Loss= 0.693581, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 210, Loss= 0.693583, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 211, Loss= 0.693588, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 212, Loss= 0.693595, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 213, Loss= 0.693598, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 214, Loss= 0.693594, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 215, Loss= 0.693584, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 216, Loss= 0.693573, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 217, Loss= 0.693567, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 218, Loss= 0.693563, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 219, Loss= 0.693561, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 220, Loss= 0.693560, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 221, Loss= 0.693558, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 222, Loss= 0.693557, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 223, Loss= 0.693556, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 224, Loss= 0.693555, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 225, Loss= 0.693554, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 226, Loss= 0.693553, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 227, Loss= 0.693552, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 228, Loss= 0.693551, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 229, Loss= 0.693550, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 230, Loss= 0.693549, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 231, Loss= 0.693548, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 232, Loss= 0.693547, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 233, Loss= 0.693545, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 234, Loss= 0.693544, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 235, Loss= 0.693543, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 236, Loss= 0.693542, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 237, Loss= 0.693541, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 238, Loss= 0.693540, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 239, Loss= 0.693539, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 240, Loss= 0.693538, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 241, Loss= 0.693537, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 242, Loss= 0.693536, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 243, Loss= 0.693535, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 244, Loss= 0.693534, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 245, Loss= 0.693534, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 246, Loss= 0.693533, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 247, Loss= 0.693532, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 248, Loss= 0.693531, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 249, Loss= 0.693530, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 250, Loss= 0.693529, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 251, Loss= 0.693528, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 252, Loss= 0.693527, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 253, Loss= 0.693526, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 254, Loss= 0.693525, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 255, Loss= 0.693524, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 256, Loss= 0.693524, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 257, Loss= 0.693523, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 258, Loss= 0.693522, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 259, Loss= 0.693521, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 260, Loss= 0.693520, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 261, Loss= 0.693520, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 262, Loss= 0.693519, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 263, Loss= 0.693518, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 264, Loss= 0.693517, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 265, Loss= 0.693516, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 266, Loss= 0.693516, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 267, Loss= 0.693515, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 268, Loss= 0.693514, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 269, Loss= 0.693514, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 270, Loss= 0.693513, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 271, Loss= 0.693512, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 272, Loss= 0.693511, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 273, Loss= 0.693511, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 274, Loss= 0.693510, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 275, Loss= 0.693509, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 276, Loss= 0.693509, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 277, Loss= 0.693508, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 278, Loss= 0.693508, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 279, Loss= 0.693507, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 280, Loss= 0.693506, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 281, Loss= 0.693506, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 282, Loss= 0.693505, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 283, Loss= 0.693505, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 284, Loss= 0.693504, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 285, Loss= 0.693504, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 286, Loss= 0.693503, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 287, Loss= 0.693502, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 288, Loss= 0.693502, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 289, Loss= 0.693501, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 290, Loss= 0.693501, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 291, Loss= 0.693500, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 292, Loss= 0.693500, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 293, Loss= 0.693500, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 294, Loss= 0.693499, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 295, Loss= 0.693499, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 296, Loss= 0.693498, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 297, Loss= 0.693498, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 298, Loss= 0.693497, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 299, Loss= 0.693497, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 300, Loss= 0.693497, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 301, Loss= 0.693496, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 302, Loss= 0.693496, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 303, Loss= 0.693495, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 304, Loss= 0.693495, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 305, Loss= 0.693495, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 306, Loss= 0.693494, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 307, Loss= 0.693494, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 308, Loss= 0.693494, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 309, Loss= 0.693493, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 310, Loss= 0.693493, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 311, Loss= 0.693493, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 312, Loss= 0.693492, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 313, Loss= 0.693492, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 314, Loss= 0.693492, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 315, Loss= 0.693491, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 316, Loss= 0.693491, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 317, Loss= 0.693491, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 318, Loss= 0.693491, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 319, Loss= 0.693490, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 320, Loss= 0.693490, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 321, Loss= 0.693490, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 322, Loss= 0.693489, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 323, Loss= 0.693489, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 324, Loss= 0.693489, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 325, Loss= 0.693489, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 326, Loss= 0.693489, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 327, Loss= 0.693488, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 328, Loss= 0.693488, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 329, Loss= 0.693488, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 330, Loss= 0.693488, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 331, Loss= 0.693488, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 332, Loss= 0.693487, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 333, Loss= 0.693487, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 334, Loss= 0.693487, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 335, Loss= 0.693487, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 336, Loss= 0.693487, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 337, Loss= 0.693486, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 338, Loss= 0.693486, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 339, Loss= 0.693486, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 340, Loss= 0.693486, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 341, Loss= 0.693486, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 342, Loss= 0.693486, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 343, Loss= 0.693486, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 344, Loss= 0.693485, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 345, Loss= 0.693485, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 346, Loss= 0.693485, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 347, Loss= 0.693485, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 348, Loss= 0.693485, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 349, Loss= 0.693485, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 350, Loss= 0.693485, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 351, Loss= 0.693485, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 352, Loss= 0.693485, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 353, Loss= 0.693484, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 354, Loss= 0.693484, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 355, Loss= 0.693484, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 356, Loss= 0.693484, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 357, Loss= 0.693484, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 358, Loss= 0.693484, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 359, Loss= 0.693484, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 360, Loss= 0.693484, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 361, Loss= 0.693484, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 362, Loss= 0.693484, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 363, Loss= 0.693484, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 364, Loss= 0.693484, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 365, Loss= 0.693484, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 366, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 367, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 368, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 369, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 370, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 371, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 372, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 373, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 374, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 375, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 376, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 377, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 378, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 379, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 380, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 381, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 382, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 383, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 384, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 385, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 386, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 387, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 388, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 389, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 390, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 391, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 392, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 393, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 394, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 395, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 396, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 397, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 398, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 399, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 400, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 401, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 402, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 403, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 404, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 405, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 406, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 407, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 408, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 409, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 410, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 411, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 412, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 413, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 414, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 415, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 416, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 417, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 418, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 419, Loss= 0.693483, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(init)\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    best_acc = 0.\n",
    "    summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
    "    num_batches = len(train_idx)//batch_size\n",
    "    \n",
    "    for i in range(training_iters):\n",
    "        \n",
    "        # Reset metrics\n",
    "        loss_total = 0\n",
    "        acc_total = 0\n",
    "        train_results = []\n",
    "   \n",
    "        # Run optimization \n",
    "        # Calculate batch loss and accuracy\n",
    "        for batch in range(num_batches):\n",
    "            batch_x = data_img[train_idx,:,:,:][batch*batch_size:min((batch+1)*batch_size,len(train_idx))]\n",
    "            batch_y = y_train_true[batch*batch_size:min((batch+1)*batch_size,len(y_train_true))]    \n",
    "\n",
    "            feed_dict={x: batch_x, y: batch_y}\n",
    "            opt = sess.run(optimizer, feed_dict=feed_dict)\n",
    "            loss, acc, pred_labels = sess.run([cost, accuracy, pred_class], feed_dict=feed_dict)\n",
    "            loss_total += loss\n",
    "            acc_total += acc\n",
    "            train_results.append(pred_labels)\n",
    "\n",
    "        # Average metrics\n",
    "        ave_loss = loss_total/num_batches\n",
    "        ave_acc = acc_total/num_batches\n",
    "\n",
    "        # Calculate accuracy for all test images\n",
    "        valid_loss, test_acc, test_results = sess.run([cost, accuracy, pred_class],\n",
    "                                feed_dict={x: data_img[test_idx,:,:,:], y : y_test_true})\n",
    "        \n",
    "        # Update metrics\n",
    "        train_loss.append(ave_loss)\n",
    "        test_loss.append(valid_loss)\n",
    "        train_accuracy.append(ave_acc)\n",
    "        test_accuracy.append(test_acc)\n",
    "        if test_acc > best_acc:\n",
    "            best_model_train_labels = tf.stack(tf.reshape(tf.stack(train_results),[-1,1])).eval()\n",
    "            best_model_test_labels = test_results\n",
    "            best_acc = test_acc\n",
    "        \n",
    "        # Print metrics\n",
    "        print(\"Iter \" + str(i) + \", Loss= \" + \\\n",
    "                      \"{:.6f}\".format(ave_loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.5f}\".format(ave_acc)+ \\\n",
    "                      \" ,Testing Accuracy:\",\"{:.5f}\".format(test_acc))\n",
    "    summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391a1ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a48e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278b614f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd16f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "for title, data in {\"Loss\":train_loss,\"Train Accuracy\": train_accuracy, \"Test Accuracy\": test_accuracy}.items():\n",
    "    plt.plot(data)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02592675",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p37)",
   "language": "python",
   "name": "conda_tensorflow_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
