{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2f7a5cc",
   "metadata": {
    "cell_id": "00000-c9411c2c-499e-47f2-8e90-48359f30a042",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache using fc-list. This may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import numpy as np\n",
    "import skimage as sk\n",
    "from skimage import transform\n",
    "import random\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fe3490c",
   "metadata": {
    "cell_id": "00001-6ee2e928-83b8-449a-a873-d56ff0f32e53",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([1.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba06b436",
   "metadata": {
    "cell_id": "00002-5fd46f44-d261-427e-b7a4-312aafd58e01",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "def rotate_img(image):\n",
    "    random_degree = random.uniform(-25, 25) #25% from left or right\n",
    "    return sk.transform.rotate(image, random_degree)\n",
    "\n",
    "def noise_img(image):\n",
    "    return sk.util.random_noise(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49b90f23",
   "metadata": {
    "cell_id": "00003-6f80fd6f-6c44-4198-a551-dbe47c35624c",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 12068069485165721096)\n",
      "_DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7860899996214059432)\n",
      "_DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 3159879680554869148)\n",
      "_DeviceAttributes(/job:localhost/replica:0/task:0/device:GPU:0, GPU, 7518981325, 8256987694415170389)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    devices = sess.list_devices()\n",
    "    for d in devices:\n",
    "        print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2597cbe6",
   "metadata": {
    "cell_id": "00004-4952f9a1-0bf2-4dd7-9b2e-9d23e70a7a5f",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "flooded_img = []\n",
    "nonflooded_img = []\n",
    "unlabeled_img = []\n",
    "\n",
    "h_dim  = 1000\n",
    "v_dim = 750\n",
    "\n",
    "root = \"Train\"\n",
    "flood_dir = os.path.join(root,'Labeled/Flooded/image/')\n",
    "nonflood_dir = os.path.join(root,'Labeled/Non-Flooded/image/')\n",
    "unlabel_dir = os.path.join(root,'Unlabeled/image/')\n",
    "\n",
    "for file in os.listdir(flood_dir):\n",
    "    image = Image.open(os.path.join(flood_dir, file))\n",
    "    image = np.array(image.resize((h_dim,v_dim)))\n",
    "    flooded_img.append(rotate_img(image))\n",
    "\n",
    "for file in os.listdir(nonflood_dir):\n",
    "    image = Image.open(os.path.join(nonflood_dir, file))\n",
    "    image = np.array(image.resize((h_dim,v_dim)))\n",
    "    nonflooded_img.append(rotate_img(image))\n",
    "    \n",
    "for file in os.listdir(unlabel_dir):\n",
    "    image = Image.open(os.path.join(unlabel_dir, file))\n",
    "    image = np.array(image.resize((h_dim,v_dim)))\n",
    "    unlabeled_img.append(rotate_img(image))\n",
    "    unlabeled_img.append(rotate_img(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a1532ef",
   "metadata": {
    "cell_id": "00005-c3f39d0e-db59-4411-8499-017ef4e209bd",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flooded Image Shape: (750, 1000, 3)\n",
      "Non_Flooded Image Shape: (750, 1000, 3)\n",
      "Unlabeled Image Shape: (750, 1000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Flooded Image Shape: {}\".format(flooded_img[0].shape))\n",
    "print(\"Non_Flooded Image Shape: {}\".format(nonflooded_img[0].shape))\n",
    "print(\"Unlabeled Image Shape: {}\".format(unlabeled_img[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cef0c525",
   "metadata": {
    "cell_id": "00006-4f946783-0b1b-4223-92ec-9844d0049d0b",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(397, 750, 1000, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_img = np.vstack((np.array(flooded_img), np.array(nonflooded_img))) / 255.\n",
    "data_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "664e449b",
   "metadata": {
    "cell_id": "00007-ed70c2c7-f64d-429d-bfdd-cffc193c8882",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(366, 750, 1000, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_img = np.array(unlabeled_img) /255.\n",
    "unlabeled_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "364afd00",
   "metadata": {
    "cell_id": "00008-47ff1934-a6bb-4968-a993-93bb1b4f1f8d",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Index: [  0   1   2   5   6   7   8  10  11  12  13  15  16  17  18  19  21  22\n",
      "  23  25  26  28  29  30  31  33  35  36  37  38  39  40  41  43  44  45\n",
      "  47  48  49  50  64  66  87  94  96 103 107 121 136 141 154 166 181 182\n",
      " 200 209 218 219 223 227 241 242 251 272 279 303 305 306 307 312 330 331\n",
      " 335 351 353 354 357 366 382 384]\n",
      "Testing Index: [  3   4   9  14  20  24  27  32  34  42  46  51  61 102 148 151 234 239\n",
      " 258 324 356 378]\n",
      "Unlabeled Training Index: [ 1  2  4  5  6  7  8  9 10 11 12 13 14 16 18 19 20 22 23 26 27 29 30 31\n",
      " 32 34 35 37 38 39 40 41 42 43 44 45 46 47 48 50]\n"
     ]
    }
   ],
   "source": [
    "#train_idx = np.array([np.arange(7),np.arange(10,17)]).flatten()\n",
    "#test_idx = np.array([np.arange(7,10),np.arange(17,20)]).flatten()\n",
    "\n",
    "test = False\n",
    "\n",
    "#n is number images from each class (flooded or non flooded)\n",
    "if test == True:\n",
    "    n = 20\n",
    "else:\n",
    "    n = min(len(flooded_img),len(nonflooded_img))\n",
    "\n",
    "\n",
    "idxs = train_test_split(n,flooded_img,nonflooded_img,unlabeled_img)\n",
    "label_train_idx, label_test_idx, train_labels, test_labels, unlabel_train_idx, unlabel_test_idx = idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39d9cf8",
   "metadata": {
    "cell_id": "00009-52c19d5d-5b6f-4c76-8cdf-5f4797fe3232",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### CNN CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f795bd7",
   "metadata": {
    "cell_id": "00010-2168eb0b-3232-4bb1-9a86-4b0739f22e7f",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# convolutional layer\n",
    "def conv_layer(x, shape):\n",
    "\n",
    "    weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "    bias = tf.Variable(tf.constant(0.05, shape=[shape[-1]]))\n",
    "\n",
    "    out = tf.nn.conv2d(input=x, filters=weights, strides=[1,1,1,1], padding='SAME')\n",
    "    out += bias\n",
    "    return out\n",
    "\n",
    "# pooling layer\n",
    "def max_pool(x, k=2):\n",
    "\n",
    "    out = tf.nn.max_pool(value=x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "    return out\n",
    "\n",
    "# fully connected layer\n",
    "def fully_connected_layer(x, shape):\n",
    "\n",
    "    weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "    bias = tf.Variable(tf.constant(0.05, shape=[shape[1]]))\n",
    "\n",
    "    out = tf.matmul(a=x, b=weights)\n",
    "    out += bias\n",
    "    return out\n",
    "\n",
    "# flatten layer\n",
    "def flatten_layer(x):\n",
    "    \n",
    "    size = x.get_shape()[1:4].num_elements()\n",
    "    out = tf.reshape(x, [-1,size])\n",
    "    return out, size\n",
    "\n",
    "# relu\n",
    "relu = lambda x: tf.nn.relu(features=x)\n",
    "\n",
    "# softmax\n",
    "softmax = lambda x: tf.nn.softmax(logits=x)\n",
    "\n",
    "# batch norm\n",
    "batch_norm = lambda x: tf.layers.batch_normalization(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9f66955",
   "metadata": {
    "cell_id": "00011-b4c7d667-ad2c-452b-9531-a66101ab4d7c",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "#shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "# define CNN\n",
    "def toy_model(x):\n",
    "\n",
    "    # Six convolutional layers with max pool and ReLU\n",
    "    shape0 = [5, 5, 3, 3]\n",
    "    conv0 = conv_layer(x, shape0)\n",
    "    conv0 = relu(conv0)\n",
    "    conv0 = batch_norm(conv0)\n",
    "    conv0 = max_pool(conv0, k=2)\n",
    "\n",
    "    shape1 = [5, 5, 3, 3]\n",
    "    conv1 = conv_layer(conv0, shape1)\n",
    "    conv1 = relu(conv1)\n",
    "    conv1 = batch_norm(conv1)\n",
    "    conv1 = max_pool(conv1, k=2)\n",
    "\n",
    "    shape2 = [5, 5, 3, 3]\n",
    "    conv2 = conv_layer(conv1, shape2)\n",
    "    conv2 = relu(conv2)\n",
    "    conv2 = batch_norm(conv2)\n",
    "    conv2 = max_pool(conv2, k=2)\n",
    "\n",
    "    shape3 = [5, 5, 3, 1]\n",
    "    conv3 = conv_layer(conv2, shape3)\n",
    "    conv3 = relu(conv3)\n",
    "    conv3 = batch_norm(conv3)\n",
    "    conv3 = max_pool(conv3, k=2)\n",
    "\n",
    "    shape4 = [5, 5, 1, 1]\n",
    "    conv4 = conv_layer(conv3, shape4)\n",
    "    conv4 = relu(conv4)\n",
    "    conv4 = batch_norm(conv4)\n",
    "    conv4 = max_pool(conv4, k=2)\n",
    "\n",
    "    shape5 = [5, 5, 1, 1]\n",
    "    conv5 = conv_layer(conv4, shape5)\n",
    "    conv5 = relu(conv5)\n",
    "    conv5 = batch_norm(conv5)\n",
    "    conv5 = max_pool(conv5, k=2)\n",
    "\n",
    "    # flatten output and put through a fully connected layer\n",
    "    flat1, size1 = flatten_layer(conv5)\n",
    "    fc1 = fully_connected_layer(flat1, [size1, 64])\n",
    "    fc1 = relu(fc1)\n",
    "\n",
    "    fc2 = fully_connected_layer(fc1, [64, 1])\n",
    "    out = softmax(fc2)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7820ba75",
   "metadata": {
    "cell_id": "00012-b85abf7e-fc25-43ab-a2c9-236ed677654c",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "def sharpen(p):\n",
    "    T = 0.5\n",
    "    pred = p**(1./T)/(p**(1./T) + (1.-p)**(1./T))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2302273d",
   "metadata": {
    "cell_id": "00013-1cb03929-e884-4721-a3b9-52efe6544e0b",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "def generate_guess_label(pred_u_raw, k):\n",
    "    # guess label = average prediction over k augmentations of same image\n",
    "    # num_images = pred_u_raw.shape[0].value / k # Throws error of NoneType and int since pred_u_raw.shape[0].value is None\n",
    "    \n",
    "    try:\n",
    "        num_images = int(pred_u_raw.shape[0].value / k)\n",
    "\n",
    "        idx = 0\n",
    "        temp_labels = []\n",
    "        for i in range(num_images):\n",
    "            temp_labels.append(tf.reduce_mean(pred_u_raw[idx:idx+k]))\n",
    "            idx += k\n",
    "\n",
    "        # repeat label for each augmentation\n",
    "        guess_labels = tf.repeat(tf.stack(temp_labels), k)\n",
    "\n",
    "        # reshape and remove gradient tracking\n",
    "        guess_labels = tf.reshape(guess_labels, (-1,1))\n",
    "        guess_labels = tf.stop_gradient(guess_labels)\n",
    "\n",
    "        return guess_labels\n",
    "\n",
    "    except TypeError:\n",
    "      \n",
    "      return pred_u_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f612b8d",
   "metadata": {
    "cell_id": "00014-18ba1d9b-88c7-4057-80eb-83f6326de7d3",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-466118caeff7>:41: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/layers/normalization.py:327: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-19-1d19f5cc381d>:26: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# define inputs\n",
    "hdim = data_img[0].shape[0]\n",
    "vdim = data_img[0].shape[1]\n",
    "x = tf.placeholder(tf.float32, [None, hdim, vdim, 3], 'x') # labeled images (augmented)\n",
    "u = tf.placeholder(tf.float32, [None, hdim, vdim, 3], 'u') # unlabeled images (augmented)\n",
    "y = tf.placeholder(tf.float32, [None, 1], 'y') # labels\n",
    "train_labels = np.array(train_labels).reshape(-1,1)\n",
    "test_labels = np.array(test_labels).reshape(-1,1)\n",
    "k = 2 # augment images k times\n",
    "\n",
    "# Google paper section 3.5 says 100 is a good place to start for w_unlabeled\n",
    "# Google paper also suggests ramping up value to 100 over first 16,000 epochs\n",
    "w_unlabeled = 100. \n",
    "\n",
    "# run model with placeholder tensors (feed forward pass)\n",
    "pred_x = toy_model(x)\n",
    "pred_u_raw = toy_model(u)\n",
    "\n",
    "# calculate guess labels for unlabeled images \n",
    "pred_u = generate_guess_label(pred_u_raw, k) # average predictions across same unlabelled images\n",
    "\n",
    "# sharpen guess labels \n",
    "pred_u = sharpen(pred_u)\n",
    "\n",
    "# define loss\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=pred_x, labels=y)\n",
    "labeled_loss = tf.reduce_mean(cross_entropy)\n",
    "unlabeled_loss = tf.nn.l2_loss(pred_u - pred_u_raw)\n",
    "cost = labeled_loss + w_unlabeled*unlabeled_loss\n",
    "\n",
    "# define accuracy\n",
    "pred_correct = tf.equal(tf.argmax(pred_x, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(pred_correct, tf.float32))\n",
    "\n",
    "# define optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "\n",
    "# initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "training_iters = 5\n",
    "batch_size = 4 #len(train_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ba3d2c",
   "metadata": {
    "cell_id": "00015-ec89594c-d9f7-4a28-9b80-390376ed16a3",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe3fc365",
   "metadata": {
    "cell_id": "00016-6678dcec-4993-4099-b271-9dcc00ef6313",
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Testing Accuracy: 1.00000\n",
      "Iter 1, Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Testing Accuracy: 1.00000\n",
      "Iter 2, Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Testing Accuracy: 1.00000\n",
      "Iter 3, Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Testing Accuracy: 1.00000\n",
      "Iter 4, Loss= 0.000000, Training Accuracy= 1.00000\n",
      "Testing Accuracy: 1.00000\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
    "    num_batches = len(label_train_idx)//batch_size\n",
    "\n",
    "    \n",
    "    for i in range(training_iters):\n",
    "        \n",
    "        # Reset metrics\n",
    "        loss_total = 0\n",
    "        acc_total = 0\n",
    "   \n",
    "        # Run optimization \n",
    "        # Calculate batch loss and accuracy\n",
    "        for batch in range(num_batches):\n",
    "            batch_x = data_img[label_train_idx,:,:,:][batch*batch_size:min((batch+1)*batch_size, len(label_train_idx))]\n",
    "            batch_u = unlabeled_img[unlabel_train_idx,:,:,:][batch*k*batch_size:min((batch+1)*k*batch_size, len(unlabel_train_idx))]\n",
    "            batch_y = train_labels[batch*batch_size:min((batch+1)*batch_size, len(train_labels))]\n",
    "\n",
    "            feed_dict={x: batch_x, u: batch_u, y: batch_y}\n",
    "            opt = sess.run(optimizer, feed_dict=feed_dict)\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict=feed_dict)\n",
    "            loss_total += loss\n",
    "            acc_total += acc\n",
    "\n",
    "        # Average metrics\n",
    "        ave_loss = loss_total/num_batches\n",
    "        ave_acc = acc_total/num_batches\n",
    "\n",
    "        print(\"Iter \" + str(i) + \", Loss= \" + \\\n",
    "                      \"{:.6f}\".format(ave_loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.5f}\".format(ave_acc))\n",
    "\n",
    "        # Calculate accuracy for all test images\n",
    "        test_acc,valid_loss = sess.run([accuracy,cost],\n",
    "                                feed_dict={x: data_img[label_test_idx,:,:,:], u: unlabeled_img[unlabel_test_idx,:,:,:], y : test_labels})\n",
    "        train_loss.append(ave_loss)\n",
    "        test_loss.append(valid_loss)\n",
    "        train_accuracy.append(ave_acc)\n",
    "        test_accuracy.append(test_acc)\n",
    "        print(\"Testing Accuracy:\",\"{:.5f}\".format(test_acc))\n",
    "    summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed9f406f",
   "metadata": {
    "cell_id": "00017-1e25c9a4-adb4-4ddb-9aa6-f99c36bb0c89",
    "deepnote_cell_type": "code",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAQy0lEQVR4nO3dfZBddX3H8ffHBIOtLU+JCIS4tKQ6wY7YuSJW7TAIGFo1jGVG0GpmSidtR1ofR2O18qB/QG2FdsTOZMSRUQs6WGuqbWPkoVJLIRtENCAlIgwJYIJBhFrBwLd/3JN22W4eNvcmd9ff+zWzk3vO+d2z371D8t577u4lVYUkqV3PGPUAkqTRMgSS1DhDIEmNMwSS1DhDIEmNMwSS1DhDIEmNMwTSLiS5J8kpo55D2pcMgSQ1zhBI05RkXpJLk9zffVyaZF53bH6SLyf5UZJtSW5I8ozu2HuTbE7yaJI7k7xqtF+J1Dd31ANIs9D7gROB44ECvgR8APhz4F3AJmBBt/ZEoJI8HzgXeElV3Z9kDJizf8eWpuYzAmn63gRcWFVbqmorcAHw5u7Yz4AjgOdV1c+q6obqv6HXk8A8YEmSA6rqnqr63kimlyYxBNL0HQncO2H73m4fwEeAjcBXk9ydZCVAVW0E3g6cD2xJclWSI5FmAEMgTd/9wPMmbC/q9lFVj1bVu6rqV4DXAe/c8VpAVf1dVb2iu28BF+/fsaWpGQJp9w5IcuCOD+BK4ANJFiSZD3wQ+AxAktckOTZJgEfoXxJ6Ksnzk5zcvaj8U+C/gadG8+VIT2cIpN37J/r/cO/4OBAYB24Dvg3cAny4W7sY+BrwGHAj8PGquo7+6wMXAQ8BDwLPAd63/74Eaefi/5hGktrmMwJJapwhkKTGGQJJapwhkKTGzcq3mJg/f36NjY2NegxJmlXWr1//UFUtmLx/VoZgbGyM8fHxUY8hSbNKknun2u+lIUlqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklqnCGQpMYZAklq3FBCkGRpkjuTbEyycorj85J8rjt+U5KxSccXJXksybuHMY8kac8NHIIkc4DLgNOBJcDZSZZMWnYO8HBVHQtcAlw86fhHgX8edBZJ0vQN4xnBCcDGqrq7qp4ArgKWTVqzDLiiu3018KokAUhyBvB9YMMQZpEkTdMwQnAUcN+E7U3dvinXVNV24BHgsCTPBt4LXLC7T5JkRZLxJONbt24dwtiSJBj9i8XnA5dU1WO7W1hVq6qqV1W9BQsW7PvJJKkRc4dwjs3A0RO2F3b7plqzKclc4CDgh8BLgTOT/AVwMPBUkp9W1ceGMJckaQ8MIwTrgMVJjqH/D/5ZwBsnrVkNLAduBM4Erq2qAl65Y0GS84HHjIAk7V8Dh6Cqtic5F1gDzAE+WVUbklwIjFfVauBy4NNJNgLb6MdCkjQDpP+N+ezS6/VqfHx81GNI0qySZH1V9SbvH/WLxZKkETMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktS4oYQgydIkdybZmGTlFMfnJflcd/ymJGPd/lOTrE/y7e7Pk4cxjyRpzw0cgiRzgMuA04ElwNlJlkxadg7wcFUdC1wCXNztfwh4bVX9OrAc+PSg80iSpmcYzwhOADZW1d1V9QRwFbBs0pplwBXd7auBVyVJVX2zqu7v9m8AnpVk3hBmkiTtoWGE4Cjgvgnbm7p9U66pqu3AI8Bhk9b8LnBLVT0+hJkkSXto7qgHAEhyHP3LRaftYs0KYAXAokWL9tNkkvTzbxjPCDYDR0/YXtjtm3JNkrnAQcAPu+2FwBeBt1TV93b2SapqVVX1qqq3YMGCIYwtSYLhhGAdsDjJMUmeCZwFrJ60ZjX9F4MBzgSurapKcjDwFWBlVX1jCLNIkqZp4BB01/zPBdYAdwCfr6oNSS5M8rpu2eXAYUk2Au8EdvyI6bnAscAHk9zafTxn0JkkSXsuVTXqGaat1+vV+Pj4qMeQpFklyfqq6k3e728WS1LjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjhhKCJEuT3JlkY5KVUxyfl+Rz3fGbkoxNOPa+bv+dSV49jHkkSXtu4BAkmQNcBpwOLAHOTrJk0rJzgIer6ljgEuDi7r5LgLOA44ClwMe780mS9pO5QzjHCcDGqrobIMlVwDLg9glrlgHnd7evBj6WJN3+q6rqceD7STZ257txCHP9Pxf84wZuv//H++LUkrTPLTnylznvtccN/bzDuDR0FHDfhO1N3b4p11TVduAR4LA9vC8ASVYkGU8yvnXr1iGMLUmC4Twj2C+qahWwCqDX69XenGNflFSSZrthPCPYDBw9YXtht2/KNUnmAgcBP9zD+0qS9qFhhGAdsDjJMUmeSf/F39WT1qwGlne3zwSurarq9p/V/VTRMcBi4OYhzCRJ2kMDXxqqqu1JzgXWAHOAT1bVhiQXAuNVtRq4HPh092LwNvqxoFv3efovLG8H3lpVTw46kyRpz6X/jfns0uv1anx8fNRjSNKskmR9VfUm7/c3iyWpcYZAkhpnCCSpcYZAkhpnCCSpcYZAkhpnCCSpcYZAkhpnCCSpcYZAkhpnCCSpcYZAkhpnCCSpcYZAkhpnCCSpcYZAkhpnCCSpcYZAkhpnCCSpcYZAkhpnCCSpcYZAkhpnCCSpcYZAkhpnCCSpcYZAkhpnCCSpcYZAkhpnCCSpcYZAkho3UAiSHJpkbZK7uj8P2cm65d2au5Is7/b9QpKvJPlukg1JLhpkFknS3hn0GcFK4JqqWgxc020/TZJDgfOAlwInAOdNCMZfVtULgBcDL09y+oDzSJKmadAQLAOu6G5fAZwxxZpXA2uraltVPQysBZZW1U+q6jqAqnoCuAVYOOA8kqRpGjQEh1fVA93tB4HDp1hzFHDfhO1N3b7/leRg4LX0n1VIkvajubtbkORrwHOnOPT+iRtVVUlqugMkmQtcCfxNVd29i3UrgBUAixYtmu6nkSTtxG5DUFWn7OxYkh8kOaKqHkhyBLBlimWbgZMmbC8Erp+wvQq4q6ou3c0cq7q19Hq9aQdHkjS1QS8NrQaWd7eXA1+aYs0a4LQkh3QvEp/W7SPJh4GDgLcPOIckaS8NGoKLgFOT3AWc0m2TpJfkEwBVtQ34ELCu+7iwqrYlWUj/8tIS4JYktyb5gwHnkSRNU6pm31WWXq9X4+Pjox5DkmaVJOurqjd5v79ZLEmNMwSS1DhDIEmNMwSS1DhDIEmNMwSS1DhDIEmNMwSS1DhDIEmNMwSS1DhDIEmNMwSS1DhDIEmNMwSS1DhDIEmNMwSS1DhDIEmNMwSS1DhDIEmNMwSS1DhDIEmNMwSS1DhDIEmNMwSS1DhDIEmNMwSS1DhDIEmNMwSS1DhDIEmNMwSS1DhDIEmNGygESQ5NsjbJXd2fh+xk3fJuzV1Jlk9xfHWS7wwyiyRp7wz6jGAlcE1VLQau6bafJsmhwHnAS4ETgPMmBiPJ64HHBpxDkrSXBg3BMuCK7vYVwBlTrHk1sLaqtlXVw8BaYClAkmcD7wQ+POAckqS9NGgIDq+qB7rbDwKHT7HmKOC+Cdubun0AHwL+CvjJ7j5RkhVJxpOMb926dYCRJUkTzd3dgiRfA547xaH3T9yoqkpSe/qJkxwP/GpVvSPJ2O7WV9UqYBVAr9fb488jSdq13Yagqk7Z2bEkP0hyRFU9kOQIYMsUyzYDJ03YXghcD7wM6CW5p5vjOUmur6qTkCTtN4NeGloN7PgpoOXAl6ZYswY4Lckh3YvEpwFrqupvq+rIqhoDXgH8pxGQpP1v0BBcBJya5C7glG6bJL0knwCoqm30XwtY131c2O2TJM0AqZp9l9t7vV6Nj4+PegxJmlWSrK+q3uT9/maxJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS4wyBJDXOEEhS41JVo55h2pJsBe7dy7vPBx4a4jg/73y8psfHa3p8vKZn0MfreVW1YPLOWRmCQSQZr6reqOeYLXy8psfHa3p8vKZnXz1eXhqSpMYZAklqXIshWDXqAWYZH6/p8fGaHh+v6dknj1dzrxFIkp6uxWcEkqQJDIEkNa6ZECRZmuTOJBuTrBz1PDNdkk8m2ZLkO6OeZTZIcnSS65LcnmRDkreNeqaZLMmBSW5O8q3u8bpg1DPNBknmJPlmki8P87xNhCDJHOAy4HRgCXB2kiWjnWrG+xSwdNRDzCLbgXdV1RLgROCt/je2S48DJ1fVi4DjgaVJThzxTLPB24A7hn3SJkIAnABsrKq7q+oJ4Cpg2YhnmtGq6uvAtlHPMVtU1QNVdUt3+1H6f1mPGu1UM1f1PdZtHtB9+JMru5BkIfA7wCeGfe5WQnAUcN+E7U34l1T7SJIx4MXATaOdZGbrLnPcCmwB1laVj9euXQq8B3hq2CduJQTSfpHk2cAXgLdX1Y9HPc9MVlVPVtXxwELghCQvHPVMM1WS1wBbqmr9vjh/KyHYDBw9YXtht08amiQH0I/AZ6vq70c9z2xRVT8CrsPXpHbl5cDrktxD/9L2yUk+M6yTtxKCdcDiJMckeSZwFrB6xDPp50iSAJcDd1TVR0c9z0yXZEGSg7vbzwJOBb472qlmrqp6X1UtrKox+v9+XVtVvzes8zcRgqraDpwLrKH/It7nq2rDaKea2ZJcCdwIPD/JpiTnjHqmGe7lwJvpf6d2a/fx26MeagY7ArguyW30v1FbW1VD/ZFI7TnfYkKSGtfEMwJJ0s4ZAklqnCGQpMYZAklqnCGQpMYZAjUtyWPdn2NJ3jjkc//ZpO1/H+b5pWExBFLfGDCtECSZu5slTwtBVf3mNGeS9gtDIPVdBLyy+0Wwd3RviPaRJOuS3JbkDwGSnJTkhiSrgdu7ff+QZH33vvorun0XAc/qzvfZbt+OZx/pzv2dJN9O8oYJ574+ydVJvpvks91vLEv71O6+o5FasRJ4d1W9BqD7B/2RqnpJknnAN5J8tVv7G8ALq+r73fbvV9W27q0S1iX5QlWtTHJu96Zqk72e/nvwvwiY393n692xFwPHAfcD36D/G8v/NvwvV/o/PiOQpnYa8JbubZJvAg4DFnfHbp4QAYA/TfIt4D/ov7nhYnbtFcCV3btv/gD4V+AlE869qaqeAm6lf8lK2qd8RiBNLcCfVNWap+1MTgL+a9L2KcDLquonSa4HDhzg8z4+4faT+HdU+4HPCKS+R4FfmrC9Bvjj7q2lSfJrSX5xivsdBDzcReAF9P83lTv8bMf9J7kBeEP3OsQC4LeAm4fyVUh7we82pL7bgCe7SzyfAv6a/mWZW7oXbLcCZ0xxv38B/ijJHcCd9C8P7bAKuC3JLVX1pgn7vwi8DPgW/f8943uq6sEuJNJ+57uPSlLjvDQkSY0zBJLUOEMgSY0zBJLUOEMgSY0zBJLUOEMgSY37H0q0G7FGp+IHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for title, data in {\"Loss\":train_loss,\"Train Accuracy\": train_accuracy, \"Test Accuracy\": test_accuracy}.items():\n",
    "    plt.plot(data)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.xticks(range(training_iters))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "8adeeecf-006d-4ae5-93da-09179c95980c",
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p37)",
   "language": "python",
   "name": "conda_tensorflow_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
