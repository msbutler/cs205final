{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f07c8493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "987367f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31e7555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For moving all img files from one root dir to another\n",
    "# source = \"Train\"\n",
    "# dest = \"Train1\"\n",
    "\n",
    "# label_flood_dir = os.path.join('Labeled','Flooded','image')\n",
    "# label_nonflood_dir = os.path.join('Labeled','Non-Flooded','image')\n",
    "\n",
    "# for dire in label_flood_dir,label_nonflood_dir:\n",
    "#     source_dir = os.path.join(source,dire)\n",
    "#     dest_dir = os.path.join(dest,dire)\n",
    "#     for file in os.listdir(source_dir):\n",
    "#         source_file = os.path.join(source_dir,file)\n",
    "#         dest_file = os.path.join(dest_dir,file)\n",
    "#         os.rename(source_file,dest_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7554149c",
   "metadata": {},
   "source": [
    "Should take around 3 minutes to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b807b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data from Memory\n",
      "Loaded!\n"
     ]
    }
   ],
   "source": [
    "h_dim = 1000\n",
    "v_dim = 750\n",
    "print(\"Loading Data from Memory\")\n",
    "\n",
    "root = \"Train\"\n",
    "label_flood_dir = os.path.join(root,'Labeled','Flooded','image')\n",
    "label_nonflood_dir = os.path.join(root,'Labeled','Non-Flooded','image')\n",
    "flooded_img = []\n",
    "nonflooded_img = []\n",
    "\n",
    "for file in os.listdir(label_flood_dir):\n",
    "    image = Image.open(os.path.join(label_flood_dir, file))\n",
    "    flooded_img.append(np.array(image.resize((h_dim,v_dim))))\n",
    "    \n",
    "for file in os.listdir(label_nonflood_dir):\n",
    "    image = Image.open(os.path.join(label_nonflood_dir, file))\n",
    "    nonflooded_img.append(np.array(image.resize((h_dim,v_dim))))\n",
    "print(\"Loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f26586fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flooded Image Shape: (750, 1000, 3)\n",
      "Non_Flooded Image Shape: (750, 1000, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(397, 750, 1000, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Flooded Image Shape: {}\".format(flooded_img[0].shape))\n",
    "print(\"Non_Flooded Image Shape: {}\".format(nonflooded_img[0].shape))\n",
    "\n",
    "data_img = np.vstack((np.array(flooded_img), np.array(nonflooded_img))) / 255.\n",
    "data_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d3ee3dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Index: [  0   1   2   3   4   5   6   7   9  10  11  13  14  15  16  18  20  22\n",
      "  23  25  26  27  28  29  30  32  35  36  37  38  39  40  42  43  44  45\n",
      "  46  47  49  50  53  75 111 124 130 148 163 165 166 172 176 184 190 212\n",
      " 218 225 242 251 257 280 283 286 289 294 300 309 310 313 316 317 334 350\n",
      " 355 358 361 372 383 386 387 393]\n",
      "Testing Index: [  8  12  17  19  21  24  31  33  34  41  48  69  81 134 141 188 233 275\n",
      " 285 306 348 389]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "test = False\n",
    "\n",
    "#n is number images from each class (flooded or non flooded)\n",
    "if test == True:\n",
    "    n = 20\n",
    "    #train_idx = np.array([np.arange(7),np.arange(10,17)]).flatten()\n",
    "    #test_idx = np.array([np.arange(7,10),np.arange(17,20)]).flatten()\n",
    "else:\n",
    "    n = min(len(flooded_img),len(nonflooded_img))\n",
    "\n",
    "'''split data 50 50'''\n",
    "def train_test_split(n):\n",
    "    idxs = list(range(n))\n",
    "    s = int(np.floor(0.8*n)) # number of images for training\n",
    "    \n",
    "    train_idx = []\n",
    "    test_idx = []\n",
    "    \n",
    "    #index range to select from (flooded img range, non flooded image range)\n",
    "    for s_i,e_i in [(0,len(flooded_img)),(len(flooded_img),len(data_img))]:\n",
    "        \n",
    "        #print(s_i,e_i,n,s)\n",
    "        #get all poss indexes for set\n",
    "        s_idx = list(range(s_i,e_i))\n",
    "        random.shuffle(s_idx)\n",
    "        \n",
    "        train_idx.extend(s_idx[:s])      #first s images are for training\n",
    "        test_idx.extend(s_idx[s:n])      # next n-s images are for testing. \n",
    "        #print(len(train_idx))\n",
    "    \n",
    "    train_idx = np.array(train_idx)\n",
    "    test_idx = np.array(test_idx)\n",
    "    train_idx.sort()\n",
    "    test_idx.sort()\n",
    "    \n",
    "    train_labels = [1 if x<len(flooded_img) else 0 for x in train_idx]\n",
    "    test_labels = [1 if x<len(flooded_img) else 0 for x in test_idx]\n",
    "\n",
    "    print(\"Training Index: {}\".format(train_idx))\n",
    "    print(\"Testing Index: {}\".format(test_idx))\n",
    "    return train_idx, test_idx, train_labels, test_labels\n",
    "\n",
    "train_idx, test_idx, train_labels, test_labels = train_test_split(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f174344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutional layer\n",
    "# x the input \n",
    "# shape is dimension of input\n",
    "def conv_layer(x, shape):\n",
    "\n",
    "    weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "    bias = tf.Variable(tf.constant(0.05, shape=[shape[-1]]))\n",
    "\n",
    "    out = tf.nn.conv2d(input=x, filters=weights, strides=[1,1,1,1], padding='SAME')\n",
    "    out += bias\n",
    "    return out\n",
    "\n",
    "# pooling layer\n",
    "def max_pool(x, k=2):\n",
    "\n",
    "    out = tf.nn.max_pool(value=x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "    return out\n",
    "\n",
    "# fully connected layer\n",
    "def fully_connected_layer(x, shape):\n",
    "\n",
    "    weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "    bias = tf.Variable(tf.constant(0.05, shape=[shape[1]]))\n",
    "\n",
    "    out = tf.matmul(a=x, b=weights)\n",
    "    out += bias\n",
    "    return out\n",
    "\n",
    "# flatten layer\n",
    "def flatten_layer(x):\n",
    "    \n",
    "    size = x.get_shape()[1:4].num_elements()\n",
    "    out = tf.reshape(x, [-1,size])\n",
    "    return out, size\n",
    "\n",
    "# relu\n",
    "relu = lambda x: tf.nn.relu(features=x)\n",
    "\n",
    "# softmax\n",
    "softmax = lambda x: tf.nn.softmax(logits=x)\n",
    "\n",
    "# sigmoid\n",
    "sigmoid = lambda x: tf.nn.sigmoid(x)\n",
    "\n",
    "# batch norm\n",
    "batch_norm = lambda x: tf.layers.batch_normalization(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "23470b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define CNN\n",
    "def toy_model(x):\n",
    "\n",
    "    # Six convolutional layers with max pool and ReLU\n",
    "    shape0 = [5, 5, 3, 3]\n",
    "    conv0 = conv_layer(x, shape0)\n",
    "    conv0 = relu(conv0)\n",
    "    conv0 = batch_norm(conv0)\n",
    "    conv0 = max_pool(conv0, k=2)\n",
    "\n",
    "    shape1 = [5, 5, 3, 3]\n",
    "    conv1 = conv_layer(conv0, shape1)\n",
    "    conv1 = relu(conv1)\n",
    "    conv1 = batch_norm(conv1)\n",
    "    conv1 = max_pool(conv1, k=2)\n",
    "\n",
    "    shape2 = [5, 5, 3, 3]\n",
    "    conv2 = conv_layer(conv1, shape2)\n",
    "    conv2 = relu(conv2)\n",
    "    conv2 = batch_norm(conv2)\n",
    "    conv2 = max_pool(conv2, k=2)\n",
    "\n",
    "    shape3 = [5, 5, 3, 1]\n",
    "    conv3 = conv_layer(conv2, shape3)\n",
    "    conv3 = relu(conv3)\n",
    "    conv3 = batch_norm(conv3)\n",
    "    conv3 = max_pool(conv3, k=2)\n",
    "\n",
    "    shape4 = [5, 5, 1, 1]\n",
    "    conv4 = conv_layer(conv3, shape4)\n",
    "    conv4 = relu(conv4)\n",
    "    conv4 = batch_norm(conv4)\n",
    "    conv4 = max_pool(conv4, k=2)\n",
    "\n",
    "    shape5 = [5, 5, 1, 1]\n",
    "    conv5 = conv_layer(conv4, shape5)\n",
    "    conv5 = relu(conv5)\n",
    "    conv5 = batch_norm(conv5)\n",
    "    conv5 = max_pool(conv5, k=2)\n",
    "\n",
    "    # flatten output and put through a fully connected layer\n",
    "    flat1, size1 = flatten_layer(conv5)\n",
    "    fc1 = fully_connected_layer(flat1, [size1, 64])\n",
    "    fc1 = relu(fc1)\n",
    "\n",
    "    fc2 = fully_connected_layer(fc1, [64, 1])\n",
    "\n",
    "    return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37a79a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpen(p):\n",
    "    T = 0.5\n",
    "    pred = p**(1./T)/(p**(1./T) + (1.-p)**(1./T))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "49b8f703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define inputs\n",
    "x = tf.placeholder(tf.float32, [None, v_dim, h_dim, 3])\n",
    "y = tf.placeholder(tf.float32, [None, 1])\n",
    "y_train_true = np.array(train_labels).reshape(-1,1)\n",
    "y_test_true = np.array(test_labels).reshape(-1,1)\n",
    "\n",
    "# run model with placeholder tensors\n",
    "pred = toy_model(x)\n",
    "\n",
    "# sharpen\n",
    "# pred = sharpen(pred)\n",
    "\n",
    "# define loss\n",
    "cross_entropy = tf.losses.sigmoid_cross_entropy(logits=pred, multi_class_labels=y)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# define accuracy\n",
    "pred_class = tf.round(sigmoid(pred))\n",
    "pred_correct = tf.equal(pred_class, tf.cast(y, tf.float32))\n",
    "accuracy = tf.reduce_mean(tf.cast(pred_correct, tf.float32))\n",
    "\n",
    "# define optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cost)\n",
    "\n",
    "# initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "training_iters = 1000\n",
    "batch_size = 20 #len(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c10a870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Loss= 0.698491, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 1, Loss= 0.694688, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 2, Loss= 0.694031, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 3, Loss= 0.693732, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 4, Loss= 0.693574, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 5, Loss= 0.693462, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 6, Loss= 0.693397, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 7, Loss= 0.693353, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 8, Loss= 0.693316, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 9, Loss= 0.693282, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 10, Loss= 0.693255, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 11, Loss= 0.693233, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 12, Loss= 0.693215, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 13, Loss= 0.693200, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 14, Loss= 0.693189, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 15, Loss= 0.693179, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 16, Loss= 0.693170, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 17, Loss= 0.693163, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 18, Loss= 0.693158, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 19, Loss= 0.693153, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 20, Loss= 0.693150, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 21, Loss= 0.693147, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 22, Loss= 0.693144, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 23, Loss= 0.693143, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 24, Loss= 0.693142, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 25, Loss= 0.693142, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 26, Loss= 0.693142, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 27, Loss= 0.693142, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 28, Loss= 0.693140, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 29, Loss= 0.693141, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 30, Loss= 0.693142, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 31, Loss= 0.693142, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 32, Loss= 0.693143, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 33, Loss= 0.693143, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 34, Loss= 0.693144, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 35, Loss= 0.693145, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 36, Loss= 0.693145, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 37, Loss= 0.693146, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 38, Loss= 0.693146, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 39, Loss= 0.693146, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 40, Loss= 0.693147, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 41, Loss= 0.693147, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 42, Loss= 0.693147, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 43, Loss= 0.693148, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 44, Loss= 0.693148, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 45, Loss= 0.693148, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 46, Loss= 0.693149, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 47, Loss= 0.693149, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 48, Loss= 0.693149, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 49, Loss= 0.693149, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 50, Loss= 0.693149, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 51, Loss= 0.693150, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 52, Loss= 0.693150, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 53, Loss= 0.693150, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 54, Loss= 0.693150, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 55, Loss= 0.693150, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 56, Loss= 0.693150, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 57, Loss= 0.693150, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 58, Loss= 0.693150, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 59, Loss= 0.693150, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 60, Loss= 0.693150, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 61, Loss= 0.693150, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 62, Loss= 0.693150, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 63, Loss= 0.693150, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 64, Loss= 0.693150, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 65, Loss= 0.693150, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 66, Loss= 0.693150, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 67, Loss= 0.693150, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 68, Loss= 0.693149, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 69, Loss= 0.693149, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 70, Loss= 0.693149, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 71, Loss= 0.693149, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 72, Loss= 0.693149, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 73, Loss= 0.693149, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 74, Loss= 0.693148, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 75, Loss= 0.693148, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 76, Loss= 0.693148, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 77, Loss= 0.693148, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 78, Loss= 0.693147, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 79, Loss= 0.693147, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 80, Loss= 0.693147, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 81, Loss= 0.693146, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 82, Loss= 0.693146, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 83, Loss= 0.693146, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 84, Loss= 0.693105, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 85, Loss= 0.693135, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 86, Loss= 0.693142, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 87, Loss= 0.693078, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 88, Loss= 0.693080, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 89, Loss= 0.693108, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 90, Loss= 0.693110, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 91, Loss= 0.693122, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 92, Loss= 0.693129, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 93, Loss= 0.693134, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 94, Loss= 0.693125, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 95, Loss= 0.693135, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 96, Loss= 0.693136, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 97, Loss= 0.693136, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 98, Loss= 0.693136, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 99, Loss= 0.693136, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 100, Loss= 0.693135, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 101, Loss= 0.693135, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 102, Loss= 0.693135, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 103, Loss= 0.693134, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 104, Loss= 0.693133, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 105, Loss= 0.693133, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 106, Loss= 0.693132, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 107, Loss= 0.693131, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 108, Loss= 0.693130, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 109, Loss= 0.693129, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 110, Loss= 0.693128, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 111, Loss= 0.693127, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 112, Loss= 0.693126, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 113, Loss= 0.693125, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 114, Loss= 0.693124, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 115, Loss= 0.693122, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 116, Loss= 0.693117, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 117, Loss= 0.693117, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 118, Loss= 0.693118, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 119, Loss= 0.693116, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 120, Loss= 0.693108, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 121, Loss= 0.693106, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 122, Loss= 0.693119, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 123, Loss= 0.693124, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 124, Loss= 0.693123, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 125, Loss= 0.693114, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 126, Loss= 0.693106, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 127, Loss= 0.693095, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 128, Loss= 0.693098, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 129, Loss= 0.693098, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 130, Loss= 0.693109, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 131, Loss= 0.693107, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 132, Loss= 0.693092, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 133, Loss= 0.693084, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 134, Loss= 0.693085, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 135, Loss= 0.693078, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 136, Loss= 0.693081, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 137, Loss= 0.693071, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 138, Loss= 0.693066, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 139, Loss= 0.693064, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 140, Loss= 0.693058, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 141, Loss= 0.693048, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 142, Loss= 0.693042, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 143, Loss= 0.693036, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 144, Loss= 0.693031, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 145, Loss= 0.693003, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 146, Loss= 0.692877, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 147, Loss= 0.692949, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 148, Loss= 0.692965, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 149, Loss= 0.692931, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 150, Loss= 0.692902, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 151, Loss= 0.692878, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 152, Loss= 0.692819, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 153, Loss= 0.692700, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 154, Loss= 0.692701, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 155, Loss= 0.691633, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 156, Loss= 0.692636, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 157, Loss= 0.692843, Training Accuracy= 0.51250 ,Testing Accuracy: 0.54545\n",
      "Iter 158, Loss= 0.692792, Training Accuracy= 0.52500 ,Testing Accuracy: 0.50000\n",
      "Iter 159, Loss= 0.692086, Training Accuracy= 0.52500 ,Testing Accuracy: 0.50000\n",
      "Iter 160, Loss= 0.691029, Training Accuracy= 0.66250 ,Testing Accuracy: 0.68182\n",
      "Iter 161, Loss= 0.691342, Training Accuracy= 0.63750 ,Testing Accuracy: 0.54545\n",
      "Iter 162, Loss= 0.688952, Training Accuracy= 0.70000 ,Testing Accuracy: 0.72727\n",
      "Iter 163, Loss= 0.687824, Training Accuracy= 0.72500 ,Testing Accuracy: 0.72727\n",
      "Iter 164, Loss= 0.682381, Training Accuracy= 0.83750 ,Testing Accuracy: 0.81818\n",
      "Iter 165, Loss= 0.681330, Training Accuracy= 0.77500 ,Testing Accuracy: 0.77273\n",
      "Iter 166, Loss= 0.671273, Training Accuracy= 0.81250 ,Testing Accuracy: 0.81818\n",
      "Iter 167, Loss= 0.668144, Training Accuracy= 0.77500 ,Testing Accuracy: 0.81818\n",
      "Iter 168, Loss= 0.650875, Training Accuracy= 0.81250 ,Testing Accuracy: 0.81818\n",
      "Iter 169, Loss= 0.644650, Training Accuracy= 0.77500 ,Testing Accuracy: 0.81818\n",
      "Iter 170, Loss= 0.621125, Training Accuracy= 0.81250 ,Testing Accuracy: 0.81818\n",
      "Iter 171, Loss= 0.609585, Training Accuracy= 0.78750 ,Testing Accuracy: 0.81818\n",
      "Iter 172, Loss= 0.584885, Training Accuracy= 0.80000 ,Testing Accuracy: 0.81818\n",
      "Iter 173, Loss= 0.573059, Training Accuracy= 0.78750 ,Testing Accuracy: 0.81818\n",
      "Iter 174, Loss= 0.545728, Training Accuracy= 0.80000 ,Testing Accuracy: 0.81818\n",
      "Iter 175, Loss= 0.548271, Training Accuracy= 0.75000 ,Testing Accuracy: 0.81818\n",
      "Iter 176, Loss= 0.516821, Training Accuracy= 0.75000 ,Testing Accuracy: 0.81818\n",
      "Iter 177, Loss= 0.504339, Training Accuracy= 0.76250 ,Testing Accuracy: 0.81818\n",
      "Iter 178, Loss= 0.498579, Training Accuracy= 0.75000 ,Testing Accuracy: 0.81818\n",
      "Iter 179, Loss= 0.482631, Training Accuracy= 0.76250 ,Testing Accuracy: 0.77273\n",
      "Iter 180, Loss= 0.463136, Training Accuracy= 0.76250 ,Testing Accuracy: 0.81818\n",
      "Iter 181, Loss= 0.454813, Training Accuracy= 0.76250 ,Testing Accuracy: 0.81818\n",
      "Iter 182, Loss= 0.448314, Training Accuracy= 0.76250 ,Testing Accuracy: 0.77273\n",
      "Iter 183, Loss= 0.437858, Training Accuracy= 0.77500 ,Testing Accuracy: 0.81818\n",
      "Iter 184, Loss= 0.431637, Training Accuracy= 0.77500 ,Testing Accuracy: 0.77273\n",
      "Iter 185, Loss= 0.425712, Training Accuracy= 0.77500 ,Testing Accuracy: 0.81818\n",
      "Iter 186, Loss= 0.423244, Training Accuracy= 0.77500 ,Testing Accuracy: 0.77273\n",
      "Iter 187, Loss= 0.415151, Training Accuracy= 0.77500 ,Testing Accuracy: 0.81818\n",
      "Iter 188, Loss= 0.413563, Training Accuracy= 0.77500 ,Testing Accuracy: 0.77273\n",
      "Iter 189, Loss= 0.407613, Training Accuracy= 0.77500 ,Testing Accuracy: 0.81818\n",
      "Iter 190, Loss= 0.403429, Training Accuracy= 0.78750 ,Testing Accuracy: 0.81818\n",
      "Iter 191, Loss= 0.400282, Training Accuracy= 0.78750 ,Testing Accuracy: 0.81818\n",
      "Iter 192, Loss= 0.393689, Training Accuracy= 0.78750 ,Testing Accuracy: 0.81818\n",
      "Iter 193, Loss= 0.393664, Training Accuracy= 0.80000 ,Testing Accuracy: 0.81818\n",
      "Iter 194, Loss= 0.384877, Training Accuracy= 0.80000 ,Testing Accuracy: 0.81818\n",
      "Iter 195, Loss= 0.386202, Training Accuracy= 0.80000 ,Testing Accuracy: 0.81818\n",
      "Iter 196, Loss= 0.376765, Training Accuracy= 0.80000 ,Testing Accuracy: 0.81818\n",
      "Iter 197, Loss= 0.377125, Training Accuracy= 0.80000 ,Testing Accuracy: 0.81818\n",
      "Iter 198, Loss= 0.370388, Training Accuracy= 0.80000 ,Testing Accuracy: 0.81818\n",
      "Iter 199, Loss= 0.366260, Training Accuracy= 0.80000 ,Testing Accuracy: 0.81818\n",
      "Iter 200, Loss= 0.363677, Training Accuracy= 0.80000 ,Testing Accuracy: 0.81818\n",
      "Iter 201, Loss= 0.355752, Training Accuracy= 0.82500 ,Testing Accuracy: 0.81818\n",
      "Iter 202, Loss= 0.359058, Training Accuracy= 0.80000 ,Testing Accuracy: 0.81818\n",
      "Iter 203, Loss= 0.337942, Training Accuracy= 0.82500 ,Testing Accuracy: 0.81818\n",
      "Iter 204, Loss= 0.362575, Training Accuracy= 0.80000 ,Testing Accuracy: 0.81818\n",
      "Iter 205, Loss= 0.335467, Training Accuracy= 0.83750 ,Testing Accuracy: 0.81818\n",
      "Iter 206, Loss= 0.334512, Training Accuracy= 0.82500 ,Testing Accuracy: 0.81818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 207, Loss= 0.338600, Training Accuracy= 0.83750 ,Testing Accuracy: 0.81818\n",
      "Iter 208, Loss= 0.323146, Training Accuracy= 0.83750 ,Testing Accuracy: 0.81818\n",
      "Iter 209, Loss= 0.324159, Training Accuracy= 0.85000 ,Testing Accuracy: 0.81818\n",
      "Iter 210, Loss= 0.319904, Training Accuracy= 0.86250 ,Testing Accuracy: 0.81818\n",
      "Iter 211, Loss= 0.312853, Training Accuracy= 0.86250 ,Testing Accuracy: 0.81818\n",
      "Iter 212, Loss= 0.312004, Training Accuracy= 0.86250 ,Testing Accuracy: 0.81818\n",
      "Iter 213, Loss= 0.304689, Training Accuracy= 0.86250 ,Testing Accuracy: 0.81818\n",
      "Iter 214, Loss= 0.302856, Training Accuracy= 0.87500 ,Testing Accuracy: 0.81818\n",
      "Iter 215, Loss= 0.297096, Training Accuracy= 0.90000 ,Testing Accuracy: 0.81818\n",
      "Iter 216, Loss= 0.292884, Training Accuracy= 0.91250 ,Testing Accuracy: 0.81818\n",
      "Iter 217, Loss= 0.289083, Training Accuracy= 0.91250 ,Testing Accuracy: 0.81818\n",
      "Iter 218, Loss= 0.283332, Training Accuracy= 0.91250 ,Testing Accuracy: 0.81818\n",
      "Iter 219, Loss= 0.279715, Training Accuracy= 0.91250 ,Testing Accuracy: 0.81818\n",
      "Iter 220, Loss= 0.274265, Training Accuracy= 0.91250 ,Testing Accuracy: 0.81818\n",
      "Iter 221, Loss= 0.270430, Training Accuracy= 0.92500 ,Testing Accuracy: 0.81818\n",
      "Iter 222, Loss= 0.264976, Training Accuracy= 0.92500 ,Testing Accuracy: 0.81818\n",
      "Iter 223, Loss= 0.260802, Training Accuracy= 0.92500 ,Testing Accuracy: 0.81818\n",
      "Iter 224, Loss= 0.255555, Training Accuracy= 0.92500 ,Testing Accuracy: 0.81818\n",
      "Iter 225, Loss= 0.251494, Training Accuracy= 0.93750 ,Testing Accuracy: 0.81818\n",
      "Iter 226, Loss= 0.246266, Training Accuracy= 0.93750 ,Testing Accuracy: 0.81818\n",
      "Iter 227, Loss= 0.240820, Training Accuracy= 0.93750 ,Testing Accuracy: 0.81818\n",
      "Iter 228, Loss= 0.237133, Training Accuracy= 0.93750 ,Testing Accuracy: 0.81818\n",
      "Iter 229, Loss= 0.230425, Training Accuracy= 0.93750 ,Testing Accuracy: 0.81818\n",
      "Iter 230, Loss= 0.226282, Training Accuracy= 0.93750 ,Testing Accuracy: 0.81818\n",
      "Iter 231, Loss= 0.220226, Training Accuracy= 0.93750 ,Testing Accuracy: 0.81818\n",
      "Iter 232, Loss= 0.215795, Training Accuracy= 0.93750 ,Testing Accuracy: 0.81818\n",
      "Iter 233, Loss= 0.210498, Training Accuracy= 0.93750 ,Testing Accuracy: 0.81818\n",
      "Iter 234, Loss= 0.204159, Training Accuracy= 0.93750 ,Testing Accuracy: 0.81818\n",
      "Iter 235, Loss= 0.200236, Training Accuracy= 0.93750 ,Testing Accuracy: 0.81818\n",
      "Iter 236, Loss= 0.194484, Training Accuracy= 0.93750 ,Testing Accuracy: 0.81818\n",
      "Iter 237, Loss= 0.189465, Training Accuracy= 0.93750 ,Testing Accuracy: 0.81818\n",
      "Iter 238, Loss= 0.183255, Training Accuracy= 0.93750 ,Testing Accuracy: 0.81818\n",
      "Iter 239, Loss= 0.179471, Training Accuracy= 0.93750 ,Testing Accuracy: 0.81818\n",
      "Iter 240, Loss= 0.172200, Training Accuracy= 0.95000 ,Testing Accuracy: 0.81818\n",
      "Iter 241, Loss= 0.169305, Training Accuracy= 0.95000 ,Testing Accuracy: 0.81818\n",
      "Iter 242, Loss= 0.161490, Training Accuracy= 0.95000 ,Testing Accuracy: 0.81818\n",
      "Iter 243, Loss= 0.158093, Training Accuracy= 0.95000 ,Testing Accuracy: 0.81818\n",
      "Iter 244, Loss= 0.151898, Training Accuracy= 0.95000 ,Testing Accuracy: 0.81818\n",
      "Iter 245, Loss= 0.145775, Training Accuracy= 0.95000 ,Testing Accuracy: 0.81818\n",
      "Iter 246, Loss= 0.144075, Training Accuracy= 0.95000 ,Testing Accuracy: 0.81818\n",
      "Iter 247, Loss= 0.135022, Training Accuracy= 0.95000 ,Testing Accuracy: 0.81818\n",
      "Iter 248, Loss= 0.135533, Training Accuracy= 0.95000 ,Testing Accuracy: 0.81818\n",
      "Iter 249, Loss= 0.126438, Training Accuracy= 0.95000 ,Testing Accuracy: 0.81818\n",
      "Iter 250, Loss= 0.125864, Training Accuracy= 0.95000 ,Testing Accuracy: 0.81818\n",
      "Iter 251, Loss= 0.120104, Training Accuracy= 0.95000 ,Testing Accuracy: 0.81818\n",
      "Iter 252, Loss= 0.113505, Training Accuracy= 0.95000 ,Testing Accuracy: 0.81818\n",
      "Iter 253, Loss= 0.112618, Training Accuracy= 0.95000 ,Testing Accuracy: 0.81818\n",
      "Iter 254, Loss= 0.104089, Training Accuracy= 0.96250 ,Testing Accuracy: 0.81818\n",
      "Iter 255, Loss= 0.102620, Training Accuracy= 0.96250 ,Testing Accuracy: 0.81818\n",
      "Iter 256, Loss= 0.098867, Training Accuracy= 0.96250 ,Testing Accuracy: 0.81818\n",
      "Iter 257, Loss= 0.093719, Training Accuracy= 0.96250 ,Testing Accuracy: 0.81818\n",
      "Iter 258, Loss= 0.092921, Training Accuracy= 0.96250 ,Testing Accuracy: 0.81818\n",
      "Iter 259, Loss= 0.088105, Training Accuracy= 0.96250 ,Testing Accuracy: 0.81818\n",
      "Iter 260, Loss= 0.083411, Training Accuracy= 0.97500 ,Testing Accuracy: 0.81818\n",
      "Iter 261, Loss= 0.081219, Training Accuracy= 0.97500 ,Testing Accuracy: 0.81818\n",
      "Iter 262, Loss= 0.078047, Training Accuracy= 0.97500 ,Testing Accuracy: 0.81818\n",
      "Iter 263, Loss= 0.075483, Training Accuracy= 0.97500 ,Testing Accuracy: 0.81818\n",
      "Iter 264, Loss= 0.071018, Training Accuracy= 0.97500 ,Testing Accuracy: 0.81818\n",
      "Iter 265, Loss= 0.067404, Training Accuracy= 0.98750 ,Testing Accuracy: 0.81818\n",
      "Iter 266, Loss= 0.068637, Training Accuracy= 0.98750 ,Testing Accuracy: 0.81818\n",
      "Iter 267, Loss= 0.062661, Training Accuracy= 0.98750 ,Testing Accuracy: 0.81818\n",
      "Iter 268, Loss= 0.060850, Training Accuracy= 0.98750 ,Testing Accuracy: 0.81818\n",
      "Iter 269, Loss= 0.059091, Training Accuracy= 0.98750 ,Testing Accuracy: 0.81818\n",
      "Iter 270, Loss= 0.054655, Training Accuracy= 0.98750 ,Testing Accuracy: 0.81818\n",
      "Iter 271, Loss= 0.054395, Training Accuracy= 0.98750 ,Testing Accuracy: 0.81818\n",
      "Iter 272, Loss= 0.050856, Training Accuracy= 0.98750 ,Testing Accuracy: 0.81818\n",
      "Iter 273, Loss= 0.048804, Training Accuracy= 0.98750 ,Testing Accuracy: 0.81818\n",
      "Iter 274, Loss= 0.046525, Training Accuracy= 1.00000 ,Testing Accuracy: 0.81818\n",
      "Iter 275, Loss= 0.044298, Training Accuracy= 1.00000 ,Testing Accuracy: 0.81818\n",
      "Iter 276, Loss= 0.042940, Training Accuracy= 1.00000 ,Testing Accuracy: 0.81818\n",
      "Iter 277, Loss= 0.038797, Training Accuracy= 1.00000 ,Testing Accuracy: 0.81818\n",
      "Iter 278, Loss= 0.039379, Training Accuracy= 1.00000 ,Testing Accuracy: 0.81818\n",
      "Iter 279, Loss= 0.033067, Training Accuracy= 1.00000 ,Testing Accuracy: 0.81818\n",
      "Iter 280, Loss= 0.037062, Training Accuracy= 1.00000 ,Testing Accuracy: 0.81818\n",
      "Iter 281, Loss= 0.029359, Training Accuracy= 1.00000 ,Testing Accuracy: 0.81818\n",
      "Iter 282, Loss= 0.033147, Training Accuracy= 1.00000 ,Testing Accuracy: 0.81818\n",
      "Iter 283, Loss= 0.025621, Training Accuracy= 1.00000 ,Testing Accuracy: 0.81818\n",
      "Iter 284, Loss= 0.031389, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 285, Loss= 0.022738, Training Accuracy= 1.00000 ,Testing Accuracy: 0.81818\n",
      "Iter 286, Loss= 0.032954, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 287, Loss= 0.020802, Training Accuracy= 1.00000 ,Testing Accuracy: 0.81818\n",
      "Iter 288, Loss= 0.019192, Training Accuracy= 1.00000 ,Testing Accuracy: 0.81818\n",
      "Iter 289, Loss= 0.070511, Training Accuracy= 0.98750 ,Testing Accuracy: 0.81818\n",
      "Iter 290, Loss= 0.105799, Training Accuracy= 0.95000 ,Testing Accuracy: 0.81818\n",
      "Iter 291, Loss= 0.027466, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 292, Loss= 0.057636, Training Accuracy= 0.98750 ,Testing Accuracy: 0.77273\n",
      "Iter 293, Loss= 0.025346, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 294, Loss= 0.042956, Training Accuracy= 0.98750 ,Testing Accuracy: 0.77273\n",
      "Iter 295, Loss= 0.024866, Training Accuracy= 1.00000 ,Testing Accuracy: 0.81818\n",
      "Iter 296, Loss= 0.040243, Training Accuracy= 1.00000 ,Testing Accuracy: 0.81818\n",
      "Iter 297, Loss= 0.028801, Training Accuracy= 1.00000 ,Testing Accuracy: 0.81818\n",
      "Iter 298, Loss= 0.028013, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 299, Loss= 0.027747, Training Accuracy= 1.00000 ,Testing Accuracy: 0.81818\n",
      "Iter 300, Loss= 0.018663, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 301, Loss= 0.035971, Training Accuracy= 1.00000 ,Testing Accuracy: 0.81818\n",
      "Iter 302, Loss= 0.027055, Training Accuracy= 0.98750 ,Testing Accuracy: 0.77273\n",
      "Iter 303, Loss= 0.031117, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 304, Loss= 0.047584, Training Accuracy= 0.98750 ,Testing Accuracy: 0.77273\n",
      "Iter 305, Loss= 0.017321, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 306, Loss= 0.036431, Training Accuracy= 1.00000 ,Testing Accuracy: 0.81818\n",
      "Iter 307, Loss= 0.018432, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 308, Loss= 0.014680, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 309, Loss= 0.014966, Training Accuracy= 1.00000 ,Testing Accuracy: 0.81818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 310, Loss= 0.014746, Training Accuracy= 1.00000 ,Testing Accuracy: 0.81818\n",
      "Iter 311, Loss= 0.012715, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 312, Loss= 0.011540, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 313, Loss= 0.009955, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 314, Loss= 0.009786, Training Accuracy= 1.00000 ,Testing Accuracy: 0.81818\n",
      "Iter 315, Loss= 0.009736, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 316, Loss= 0.009260, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 317, Loss= 0.008713, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 318, Loss= 0.008296, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 319, Loss= 0.008037, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 320, Loss= 0.007795, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 321, Loss= 0.007496, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 322, Loss= 0.007179, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 323, Loss= 0.006887, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 324, Loss= 0.006667, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 325, Loss= 0.006503, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 326, Loss= 0.006306, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 327, Loss= 0.006092, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 328, Loss= 0.005888, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 329, Loss= 0.005694, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 330, Loss= 0.005536, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 331, Loss= 0.005386, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 332, Loss= 0.005229, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 333, Loss= 0.005080, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 334, Loss= 0.004944, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 335, Loss= 0.004785, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 336, Loss= 0.004669, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 337, Loss= 0.004551, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 338, Loss= 0.004410, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 339, Loss= 0.004313, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 340, Loss= 0.004211, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 341, Loss= 0.004100, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 342, Loss= 0.003995, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 343, Loss= 0.003884, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 344, Loss= 0.003794, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 345, Loss= 0.003712, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 346, Loss= 0.003610, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 347, Loss= 0.003534, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 348, Loss= 0.003463, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 349, Loss= 0.003385, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 350, Loss= 0.003289, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 351, Loss= 0.003217, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 352, Loss= 0.003157, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 353, Loss= 0.003093, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 354, Loss= 0.003023, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 355, Loss= 0.002945, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 356, Loss= 0.002890, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 357, Loss= 0.002836, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 358, Loss= 0.002778, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 359, Loss= 0.002722, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 360, Loss= 0.002656, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 361, Loss= 0.002606, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 362, Loss= 0.002560, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 363, Loss= 0.002512, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 364, Loss= 0.002468, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 365, Loss= 0.002412, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 366, Loss= 0.002365, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 367, Loss= 0.002321, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 368, Loss= 0.002281, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 369, Loss= 0.002233, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 370, Loss= 0.002197, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 371, Loss= 0.002157, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 372, Loss= 0.002118, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 373, Loss= 0.002083, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 374, Loss= 0.002042, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 375, Loss= 0.002009, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 376, Loss= 0.001973, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 377, Loss= 0.001941, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 378, Loss= 0.001903, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 379, Loss= 0.001874, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 380, Loss= 0.001845, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 381, Loss= 0.001814, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 382, Loss= 0.001786, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 383, Loss= 0.001750, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 384, Loss= 0.001724, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 385, Loss= 0.001700, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 386, Loss= 0.001673, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 387, Loss= 0.001642, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 388, Loss= 0.001618, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 389, Loss= 0.001595, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 390, Loss= 0.001571, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 391, Loss= 0.001548, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 392, Loss= 0.001522, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 393, Loss= 0.001499, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 394, Loss= 0.001476, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 395, Loss= 0.001459, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 396, Loss= 0.001434, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 397, Loss= 0.001414, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 398, Loss= 0.001396, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 399, Loss= 0.001374, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 400, Loss= 0.001350, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 401, Loss= 0.001335, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 402, Loss= 0.001318, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 403, Loss= 0.001298, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 404, Loss= 0.001282, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 405, Loss= 0.001261, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 406, Loss= 0.001244, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 407, Loss= 0.001230, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 408, Loss= 0.001214, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 409, Loss= 0.001198, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 410, Loss= 0.001180, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 411, Loss= 0.001165, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 412, Loss= 0.001149, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 413, Loss= 0.001133, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 414, Loss= 0.001120, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 415, Loss= 0.001107, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 416, Loss= 0.001094, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 417, Loss= 0.001079, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 418, Loss= 0.001060, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 419, Loss= 0.001051, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 420, Loss= 0.001040, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 421, Loss= 0.001025, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 422, Loss= 0.001013, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 423, Loss= 0.000998, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 424, Loss= 0.000987, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 425, Loss= 0.000976, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 426, Loss= 0.000965, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 427, Loss= 0.000954, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 428, Loss= 0.000940, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 429, Loss= 0.000930, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 430, Loss= 0.000920, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 431, Loss= 0.000907, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 432, Loss= 0.000898, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 433, Loss= 0.000889, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 434, Loss= 0.000879, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 435, Loss= 0.000868, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 436, Loss= 0.000859, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 437, Loss= 0.000847, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 438, Loss= 0.000838, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 439, Loss= 0.000831, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 440, Loss= 0.000822, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 441, Loss= 0.000810, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 442, Loss= 0.000801, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 443, Loss= 0.000794, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 444, Loss= 0.000786, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 445, Loss= 0.000776, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 446, Loss= 0.000768, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 447, Loss= 0.000760, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 448, Loss= 0.000753, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 449, Loss= 0.000745, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 450, Loss= 0.000735, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 451, Loss= 0.000728, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 452, Loss= 0.000721, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 453, Loss= 0.000714, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 454, Loss= 0.000707, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 455, Loss= 0.000698, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 456, Loss= 0.000691, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 457, Loss= 0.000685, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 458, Loss= 0.000679, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 459, Loss= 0.000671, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 460, Loss= 0.000664, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 461, Loss= 0.000658, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 462, Loss= 0.000652, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 463, Loss= 0.000644, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 464, Loss= 0.000638, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 465, Loss= 0.000633, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 466, Loss= 0.000626, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 467, Loss= 0.000621, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 468, Loss= 0.000614, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 469, Loss= 0.000608, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 470, Loss= 0.000603, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 471, Loss= 0.000597, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 472, Loss= 0.000590, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 473, Loss= 0.000585, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 474, Loss= 0.000580, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 475, Loss= 0.000575, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 476, Loss= 0.000569, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 477, Loss= 0.000563, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 478, Loss= 0.000559, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 479, Loss= 0.000554, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 480, Loss= 0.000549, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 481, Loss= 0.000543, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 482, Loss= 0.000539, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 483, Loss= 0.000534, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 484, Loss= 0.000529, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 485, Loss= 0.000524, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 486, Loss= 0.000519, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 487, Loss= 0.000515, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 488, Loss= 0.000511, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 489, Loss= 0.000506, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 490, Loss= 0.000501, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 491, Loss= 0.000497, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 492, Loss= 0.000493, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 493, Loss= 0.000489, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 494, Loss= 0.000485, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 495, Loss= 0.000480, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 496, Loss= 0.000476, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 497, Loss= 0.000472, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 498, Loss= 0.000468, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 499, Loss= 0.000463, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 500, Loss= 0.000460, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 501, Loss= 0.000457, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 502, Loss= 0.000453, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 503, Loss= 0.000448, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 504, Loss= 0.000445, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 505, Loss= 0.000442, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 506, Loss= 0.000439, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 507, Loss= 0.000434, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 508, Loss= 0.000430, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 509, Loss= 0.000427, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 510, Loss= 0.000424, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 511, Loss= 0.000421, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 512, Loss= 0.000417, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 513, Loss= 0.000414, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 514, Loss= 0.000411, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 515, Loss= 0.000407, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 516, Loss= 0.000404, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 517, Loss= 0.000402, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 518, Loss= 0.000399, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 519, Loss= 0.000394, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 520, Loss= 0.000392, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 521, Loss= 0.000389, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 522, Loss= 0.000386, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 523, Loss= 0.000382, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 524, Loss= 0.000380, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 525, Loss= 0.000377, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 526, Loss= 0.000374, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 527, Loss= 0.000371, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 528, Loss= 0.000368, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 529, Loss= 0.000366, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 530, Loss= 0.000362, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 531, Loss= 0.000360, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 532, Loss= 0.000358, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 533, Loss= 0.000355, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 534, Loss= 0.000352, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 535, Loss= 0.000350, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 536, Loss= 0.000348, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 537, Loss= 0.000345, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 538, Loss= 0.000342, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 539, Loss= 0.000340, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 540, Loss= 0.000338, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 541, Loss= 0.000335, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 542, Loss= 0.000332, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 543, Loss= 0.000330, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 544, Loss= 0.000328, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 545, Loss= 0.000325, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 546, Loss= 0.000323, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 547, Loss= 0.000321, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 548, Loss= 0.000319, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 549, Loss= 0.000316, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 550, Loss= 0.000314, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 551, Loss= 0.000312, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 552, Loss= 0.000309, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 553, Loss= 0.000308, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 554, Loss= 0.000306, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 555, Loss= 0.000304, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 556, Loss= 0.000301, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 557, Loss= 0.000300, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 558, Loss= 0.000298, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 559, Loss= 0.000295, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 560, Loss= 0.000293, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 561, Loss= 0.000292, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 562, Loss= 0.000290, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 563, Loss= 0.000287, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 564, Loss= 0.000286, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 565, Loss= 0.000284, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 566, Loss= 0.000282, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 567, Loss= 0.000280, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 568, Loss= 0.000278, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 569, Loss= 0.000276, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 570, Loss= 0.000275, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 571, Loss= 0.000273, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 572, Loss= 0.000271, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 573, Loss= 0.000269, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 574, Loss= 0.000268, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 575, Loss= 0.000266, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 576, Loss= 0.000264, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 577, Loss= 0.000262, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 578, Loss= 0.000261, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 579, Loss= 0.000259, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 580, Loss= 0.000257, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 581, Loss= 0.000256, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 582, Loss= 0.000254, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 583, Loss= 0.000253, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 584, Loss= 0.000251, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 585, Loss= 0.000250, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 586, Loss= 0.000247, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 587, Loss= 0.000247, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 588, Loss= 0.000245, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 589, Loss= 0.000243, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 590, Loss= 0.000242, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 591, Loss= 0.000240, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 592, Loss= 0.000239, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 593, Loss= 0.000237, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 594, Loss= 0.000236, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 595, Loss= 0.000234, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 596, Loss= 0.000233, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 597, Loss= 0.000232, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 598, Loss= 0.000230, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 599, Loss= 0.000229, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 600, Loss= 0.000227, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 601, Loss= 0.000226, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 602, Loss= 0.000225, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 603, Loss= 0.000223, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 604, Loss= 0.000222, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 605, Loss= 0.000221, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 606, Loss= 0.000219, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 607, Loss= 0.000218, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 608, Loss= 0.000217, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 609, Loss= 0.000216, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 610, Loss= 0.000214, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 611, Loss= 0.000213, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 612, Loss= 0.000212, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 613, Loss= 0.000211, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 614, Loss= 0.000210, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 615, Loss= 0.000208, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 616, Loss= 0.000207, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 617, Loss= 0.000206, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 618, Loss= 0.000205, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 619, Loss= 0.000204, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 620, Loss= 0.000202, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 621, Loss= 0.000201, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 622, Loss= 0.000200, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 623, Loss= 0.000199, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 624, Loss= 0.000198, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 625, Loss= 0.000197, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 626, Loss= 0.000195, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 627, Loss= 0.000195, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 628, Loss= 0.000194, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 629, Loss= 0.000192, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 630, Loss= 0.000191, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 631, Loss= 0.000190, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 632, Loss= 0.000189, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 633, Loss= 0.000188, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 634, Loss= 0.000187, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 635, Loss= 0.000186, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 636, Loss= 0.000185, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 637, Loss= 0.000184, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 638, Loss= 0.000183, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 639, Loss= 0.000182, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 640, Loss= 0.000181, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 641, Loss= 0.000180, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 642, Loss= 0.000179, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 643, Loss= 0.000178, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 644, Loss= 0.000177, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 645, Loss= 0.000176, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 646, Loss= 0.000175, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 647, Loss= 0.000174, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 648, Loss= 0.000173, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 649, Loss= 0.000172, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 650, Loss= 0.000172, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 651, Loss= 0.000171, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 652, Loss= 0.000170, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 653, Loss= 0.000169, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 654, Loss= 0.000168, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 655, Loss= 0.000167, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 656, Loss= 0.000166, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 657, Loss= 0.000165, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 658, Loss= 0.000165, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 659, Loss= 0.000164, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 660, Loss= 0.000163, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 661, Loss= 0.000162, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 662, Loss= 0.000161, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 663, Loss= 0.000160, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 664, Loss= 0.000160, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 665, Loss= 0.000158, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 666, Loss= 0.000158, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 667, Loss= 0.000157, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 668, Loss= 0.000156, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 669, Loss= 0.000155, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 670, Loss= 0.000155, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 671, Loss= 0.000154, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 672, Loss= 0.000153, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 673, Loss= 0.000152, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 674, Loss= 0.000151, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 675, Loss= 0.000151, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 676, Loss= 0.000150, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 677, Loss= 0.000149, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 678, Loss= 0.000148, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 679, Loss= 0.000148, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 680, Loss= 0.000147, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 681, Loss= 0.000146, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 682, Loss= 0.000146, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 683, Loss= 0.000145, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 684, Loss= 0.000144, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 685, Loss= 0.000143, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 686, Loss= 0.000143, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 687, Loss= 0.000142, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 688, Loss= 0.000141, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 689, Loss= 0.000141, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 690, Loss= 0.000140, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 691, Loss= 0.000139, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 692, Loss= 0.000139, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 693, Loss= 0.000138, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 694, Loss= 0.000137, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 695, Loss= 0.000137, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 696, Loss= 0.000136, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 697, Loss= 0.000135, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 698, Loss= 0.000135, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 699, Loss= 0.000134, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 700, Loss= 0.000133, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 701, Loss= 0.000133, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 702, Loss= 0.000132, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 703, Loss= 0.000131, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 704, Loss= 0.000131, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 705, Loss= 0.000130, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 706, Loss= 0.000130, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 707, Loss= 0.000129, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 708, Loss= 0.000128, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 709, Loss= 0.000128, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 710, Loss= 0.000127, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 711, Loss= 0.000126, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 712, Loss= 0.000126, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 713, Loss= 0.000125, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 714, Loss= 0.000125, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 715, Loss= 0.000124, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 716, Loss= 0.000123, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 717, Loss= 0.000123, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 718, Loss= 0.000122, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 719, Loss= 0.000122, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 720, Loss= 0.000121, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 721, Loss= 0.000121, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 722, Loss= 0.000120, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 723, Loss= 0.000120, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 724, Loss= 0.000119, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 725, Loss= 0.000118, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 726, Loss= 0.000118, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 727, Loss= 0.000117, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 728, Loss= 0.000117, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 729, Loss= 0.000116, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 730, Loss= 0.000116, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 731, Loss= 0.000115, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 732, Loss= 0.000115, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 733, Loss= 0.000114, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 734, Loss= 0.000114, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 735, Loss= 0.000113, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 736, Loss= 0.000113, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 737, Loss= 0.000112, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 738, Loss= 0.000112, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 739, Loss= 0.000111, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 740, Loss= 0.000111, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 741, Loss= 0.000110, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 742, Loss= 0.000110, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 743, Loss= 0.000109, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 744, Loss= 0.000109, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 745, Loss= 0.000108, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 746, Loss= 0.000108, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 747, Loss= 0.000107, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 748, Loss= 0.000107, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 749, Loss= 0.000106, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 750, Loss= 0.000106, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 751, Loss= 0.000105, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 752, Loss= 0.000105, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 753, Loss= 0.000104, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 754, Loss= 0.000104, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 755, Loss= 0.000103, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 756, Loss= 0.000103, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 757, Loss= 0.000103, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 758, Loss= 0.000102, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 759, Loss= 0.000102, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 760, Loss= 0.000101, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 761, Loss= 0.000101, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 762, Loss= 0.000100, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 763, Loss= 0.000100, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 764, Loss= 0.000100, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 765, Loss= 0.000099, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 766, Loss= 0.000099, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 767, Loss= 0.000098, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 768, Loss= 0.000098, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 769, Loss= 0.000097, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 770, Loss= 0.000097, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 771, Loss= 0.000097, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 772, Loss= 0.000096, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 773, Loss= 0.000096, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 774, Loss= 0.000095, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 775, Loss= 0.000095, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 776, Loss= 0.000095, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 777, Loss= 0.000094, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 778, Loss= 0.000094, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 779, Loss= 0.000093, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 780, Loss= 0.000093, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 781, Loss= 0.000093, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 782, Loss= 0.000092, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 783, Loss= 0.000092, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 784, Loss= 0.000091, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 785, Loss= 0.000091, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 786, Loss= 0.000091, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 787, Loss= 0.000090, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 788, Loss= 0.000090, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 789, Loss= 0.000090, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 790, Loss= 0.000089, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 791, Loss= 0.000089, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 792, Loss= 0.000088, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 793, Loss= 0.000088, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 794, Loss= 0.000088, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 795, Loss= 0.000087, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 796, Loss= 0.000087, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 797, Loss= 0.000087, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 798, Loss= 0.000086, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 799, Loss= 0.000086, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 800, Loss= 0.000086, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 801, Loss= 0.000085, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 802, Loss= 0.000085, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 803, Loss= 0.000085, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 804, Loss= 0.000084, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 805, Loss= 0.000084, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 806, Loss= 0.000083, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 807, Loss= 0.000083, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 808, Loss= 0.000083, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 809, Loss= 0.000082, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 810, Loss= 0.000082, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 811, Loss= 0.000082, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 812, Loss= 0.000081, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 813, Loss= 0.000081, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 814, Loss= 0.000081, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 815, Loss= 0.000080, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 816, Loss= 0.000080, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 817, Loss= 0.000080, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 818, Loss= 0.000079, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 819, Loss= 0.000079, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 820, Loss= 0.000079, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 821, Loss= 0.000078, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 822, Loss= 0.000078, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 823, Loss= 0.000078, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 824, Loss= 0.000078, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 825, Loss= 0.000077, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 826, Loss= 0.000077, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 827, Loss= 0.000077, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 828, Loss= 0.000076, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 829, Loss= 0.000076, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 830, Loss= 0.000076, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 831, Loss= 0.000075, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 832, Loss= 0.000075, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 833, Loss= 0.000075, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 834, Loss= 0.000074, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 835, Loss= 0.000074, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 836, Loss= 0.000074, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 837, Loss= 0.000074, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 838, Loss= 0.000073, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 839, Loss= 0.000073, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 840, Loss= 0.000073, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 841, Loss= 0.000072, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 842, Loss= 0.000072, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 843, Loss= 0.000072, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 844, Loss= 0.000072, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 845, Loss= 0.000071, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 846, Loss= 0.000071, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 847, Loss= 0.000071, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 848, Loss= 0.000070, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 849, Loss= 0.000070, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 850, Loss= 0.000070, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 851, Loss= 0.000070, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 852, Loss= 0.000069, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 853, Loss= 0.000069, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 854, Loss= 0.000069, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 855, Loss= 0.000069, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 856, Loss= 0.000068, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 857, Loss= 0.000068, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 858, Loss= 0.000068, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 859, Loss= 0.000068, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 860, Loss= 0.000067, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 861, Loss= 0.000067, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 862, Loss= 0.000067, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 863, Loss= 0.000067, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 864, Loss= 0.000066, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 865, Loss= 0.000066, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 866, Loss= 0.000066, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 867, Loss= 0.000066, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 868, Loss= 0.000065, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 869, Loss= 0.000065, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 870, Loss= 0.000065, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 871, Loss= 0.000065, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 872, Loss= 0.000064, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 873, Loss= 0.000064, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 874, Loss= 0.000064, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 875, Loss= 0.000064, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 876, Loss= 0.000063, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 877, Loss= 0.000063, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 878, Loss= 0.000063, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 879, Loss= 0.000063, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 880, Loss= 0.000062, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 881, Loss= 0.000062, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 882, Loss= 0.000062, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 883, Loss= 0.000062, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 884, Loss= 0.000061, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 885, Loss= 0.000061, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 886, Loss= 0.000061, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 887, Loss= 0.000061, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 888, Loss= 0.000060, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 889, Loss= 0.000060, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 890, Loss= 0.000060, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 891, Loss= 0.000060, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 892, Loss= 0.000060, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 893, Loss= 0.000059, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 894, Loss= 0.000059, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 895, Loss= 0.000059, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 896, Loss= 0.000059, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 897, Loss= 0.000058, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 898, Loss= 0.000058, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 899, Loss= 0.000058, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 900, Loss= 0.000058, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 901, Loss= 0.000058, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 902, Loss= 0.000057, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 903, Loss= 0.000057, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 904, Loss= 0.000057, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 905, Loss= 0.000057, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 906, Loss= 0.000057, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 907, Loss= 0.000056, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 908, Loss= 0.000056, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 909, Loss= 0.000056, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 910, Loss= 0.000056, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 911, Loss= 0.000056, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 912, Loss= 0.000055, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 913, Loss= 0.000055, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 914, Loss= 0.000055, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 915, Loss= 0.000055, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 916, Loss= 0.000055, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 917, Loss= 0.000054, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 918, Loss= 0.000054, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 919, Loss= 0.000054, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 920, Loss= 0.000054, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 921, Loss= 0.000054, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 922, Loss= 0.000053, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 923, Loss= 0.000053, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 924, Loss= 0.000053, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 925, Loss= 0.000053, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 926, Loss= 0.000053, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 927, Loss= 0.000052, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 928, Loss= 0.000052, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 929, Loss= 0.000052, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 930, Loss= 0.000052, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 931, Loss= 0.000052, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 932, Loss= 0.000051, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 933, Loss= 0.000051, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 934, Loss= 0.000051, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 935, Loss= 0.000051, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 936, Loss= 0.000051, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 937, Loss= 0.000051, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 938, Loss= 0.000050, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 939, Loss= 0.000050, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 940, Loss= 0.000050, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 941, Loss= 0.000050, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 942, Loss= 0.000050, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 943, Loss= 0.000049, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 944, Loss= 0.000049, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 945, Loss= 0.000049, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 946, Loss= 0.000049, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 947, Loss= 0.000049, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 948, Loss= 0.000049, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 949, Loss= 0.000048, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 950, Loss= 0.000048, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 951, Loss= 0.000048, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 952, Loss= 0.000048, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 953, Loss= 0.000048, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 954, Loss= 0.000048, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 955, Loss= 0.000047, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 956, Loss= 0.000047, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 957, Loss= 0.000047, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 958, Loss= 0.000047, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 959, Loss= 0.000047, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 960, Loss= 0.000047, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 961, Loss= 0.000046, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 962, Loss= 0.000046, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 963, Loss= 0.000046, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 964, Loss= 0.000046, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 965, Loss= 0.000046, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 966, Loss= 0.000046, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 967, Loss= 0.000045, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 968, Loss= 0.000045, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 969, Loss= 0.000045, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 970, Loss= 0.000045, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 971, Loss= 0.000045, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 972, Loss= 0.000045, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 973, Loss= 0.000045, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 974, Loss= 0.000044, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 975, Loss= 0.000044, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 976, Loss= 0.000044, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 977, Loss= 0.000044, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 978, Loss= 0.000044, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 979, Loss= 0.000044, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 980, Loss= 0.000043, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 981, Loss= 0.000043, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 982, Loss= 0.000043, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 983, Loss= 0.000043, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 984, Loss= 0.000043, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 985, Loss= 0.000043, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 986, Loss= 0.000043, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 987, Loss= 0.000042, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 988, Loss= 0.000042, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 989, Loss= 0.000042, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 990, Loss= 0.000042, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 991, Loss= 0.000042, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 992, Loss= 0.000042, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 993, Loss= 0.000042, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 994, Loss= 0.000041, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 995, Loss= 0.000041, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 996, Loss= 0.000041, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 997, Loss= 0.000041, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 998, Loss= 0.000041, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 999, Loss= 0.000041, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(init)\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
    "    num_batches = len(train_idx)//batch_size\n",
    "    \n",
    "    for i in range(training_iters):\n",
    "        \n",
    "        # Reset metrics\n",
    "        loss_total = 0\n",
    "        acc_total = 0\n",
    "   \n",
    "        # Run optimization \n",
    "        # Calculate batch loss and accuracy\n",
    "        for batch in range(num_batches):\n",
    "            batch_x = data_img[train_idx,:,:,:][batch*batch_size:min((batch+1)*batch_size,len(train_idx))]\n",
    "            batch_y = y_train_true[batch*batch_size:min((batch+1)*batch_size,len(y_train_true))]    \n",
    "\n",
    "            feed_dict={x: batch_x, y: batch_y}\n",
    "            opt = sess.run(optimizer, feed_dict=feed_dict)\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict=feed_dict)\n",
    "            loss_total += loss\n",
    "            acc_total += acc\n",
    "\n",
    "        # Average metrics\n",
    "        ave_loss = loss_total/num_batches\n",
    "        ave_acc = acc_total/num_batches\n",
    "\n",
    "        # Calculate accuracy for all test images\n",
    "        valid_loss,test_acc = sess.run([cost,accuracy],\n",
    "                                feed_dict={x: data_img[test_idx,:,:,:], y : y_test_true})\n",
    "        train_loss.append(ave_loss)\n",
    "        test_loss.append(valid_loss)\n",
    "        train_accuracy.append(ave_acc)\n",
    "        test_accuracy.append(test_acc)\n",
    "        print(\"Iter \" + str(i) + \", Loss= \" + \\\n",
    "                      \"{:.6f}\".format(ave_loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.5f}\".format(ave_acc)+ \\\n",
    "                      \" ,Testing Accuracy:\",\"{:.5f}\".format(test_acc))\n",
    "    summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66e00794",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tried to convert 'input' to a tensor and failed. Error: Cannot create a tensor proto whose content is larger than 2GB.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    527\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    529\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1296\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    226\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 227\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    264\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m           allow_broadcast=allow_broadcast))\n\u001b[0m\u001b[1;32m    266\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    519\u001b[0m       raise ValueError(\n\u001b[0;32m--> 520\u001b[0;31m           \"Cannot create a tensor proto whose content is larger than 2GB.\")\n\u001b[0m\u001b[1;32m    521\u001b[0m     \u001b[0mtensor_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnparray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot create a tensor proto whose content is larger than 2GB.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    541\u001b[0m               observed = ops.internal_convert_to_tensor(\n\u001b[0;32m--> 542\u001b[0;31m                   values, as_ref=input_arg.is_ref).dtype.name\n\u001b[0m\u001b[1;32m    543\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1296\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    226\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 227\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    264\u001b[0m           \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m           allow_broadcast=allow_broadcast))\n\u001b[0m\u001b[1;32m    266\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    519\u001b[0m       raise ValueError(\n\u001b[0;32m--> 520\u001b[0;31m           \"Cannot create a tensor proto whose content is larger than 2GB.\")\n\u001b[0m\u001b[1;32m    521\u001b[0m     \u001b[0mtensor_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnparray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot create a tensor proto whose content is larger than 2GB.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-2eb4cb0063e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtoy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-cf6aa95df1b5>\u001b[0m in \u001b[0;36mtoy_model\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Six convolutional layers with max pool and ReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mshape0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mconv0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mconv0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mconv0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-928f9858c25e>\u001b[0m in \u001b[0;36mconv_layer\u001b[0;34m(x, shape)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name, filters)\u001b[0m\n\u001b[1;32m   2008\u001b[0m                            \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m                            \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m                            name=name)\n\u001b[0m\u001b[1;32m   2011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m                   data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[1;32m   1072\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    544\u001b[0m               raise ValueError(\n\u001b[1;32m    545\u001b[0m                   \u001b[0;34m\"Tried to convert '%s' to a tensor and failed. Error: %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m                   (input_name, err))\n\u001b[0m\u001b[1;32m    547\u001b[0m             prefix = (\"Input '%s' of '%s' Op has type %s that does not match\" %\n\u001b[1;32m    548\u001b[0m                       (input_name, op_type_name, observed))\n",
      "\u001b[0;31mValueError\u001b[0m: Tried to convert 'input' to a tensor and failed. Error: Cannot create a tensor proto whose content is larger than 2GB."
     ]
    }
   ],
   "source": [
    "feed_dict = {x: data_img[train_idx,:,:,:], y : y_test_true}\n",
    "sess.run([pred], feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8dd16f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for title, data in {\"Loss\":train_loss,\"Train Accuracy\": train_accuracy, \"Test Accuracy\": test_accuracy}.items():\n",
    "    plt.plot(data)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02592675",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p37)",
   "language": "python",
   "name": "conda_tensorflow_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
