{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f07c8493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "987367f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7554149c",
   "metadata": {},
   "source": [
    "Should take around 3 minutes to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b807b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data from Memory\n",
      "Loaded!\n"
     ]
    }
   ],
   "source": [
    "h_dim = 1000\n",
    "v_dim = 750\n",
    "print(\"Loading Data from Memory\")\n",
    "\n",
    "root = \"Train\"\n",
    "label_flood_dir = os.path.join(root,'Labeled','Flooded','image')\n",
    "label_nonflood_dir = os.path.join(root,'Labeled','Non-Flooded','image')\n",
    "flooded_img = []\n",
    "nonflooded_img = []\n",
    "\n",
    "for file in os.listdir(label_flood_dir):\n",
    "    image = Image.open(os.path.join(label_flood_dir, file))\n",
    "    flooded_img.append(np.array(image.resize((h_dim,v_dim))))\n",
    "    \n",
    "for file in os.listdir(label_nonflood_dir):\n",
    "    image = Image.open(os.path.join(label_nonflood_dir, file))\n",
    "    nonflooded_img.append(np.array(image.resize((h_dim,v_dim))))\n",
    "print(\"Loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f26586fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flooded Image Shape: (750, 1000, 3)\n",
      "Non_Flooded Image Shape: (750, 1000, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(398, 750, 1000, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Flooded Image Shape: {}\".format(flooded_img[0].shape))\n",
    "print(\"Non_Flooded Image Shape: {}\".format(nonflooded_img[0].shape))\n",
    "\n",
    "data_img = np.vstack((np.array(flooded_img), np.array(nonflooded_img))) / 255.\n",
    "data_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3ee3dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data len 51; n is 51 ;train size 40, test size 11\n",
      "Data len 347; n is 347 ;train size 277, test size 70\n",
      "Training Indices len 317\n",
      "Testing Indices len 81\n"
     ]
    }
   ],
   "source": [
    "from utils import train_test_split\n",
    "train_idx, test_idx, train_labels, test_labels = train_test_split(flooded_img, nonflooded_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f174344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutional layer\n",
    "# x the input \n",
    "# shape is dimension of input\n",
    "def conv_layer(x, shape,stride):\n",
    "    weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "    bias = tf.Variable(tf.constant(0.05, shape=[shape[-1]]))\n",
    "\n",
    "    out = tf.nn.conv2d(input=x, filters=weights, strides=stride, padding='VALID')\n",
    "    out += bias\n",
    "    return out\n",
    "\n",
    "# pooling layer\n",
    "def max_pool(x, k=2):\n",
    "\n",
    "    out = tf.nn.max_pool(value=x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='VALID')\n",
    "    return out\n",
    "\n",
    "# fully connected layer\n",
    "def fully_connected_layer(x, shape):\n",
    "    weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "    bias = tf.Variable(tf.constant(0.05, shape=[shape[1]]))\n",
    "\n",
    "    out = tf.matmul(a=x, b=weights)\n",
    "    out += bias\n",
    "    return out\n",
    "\n",
    "# flatten layer\n",
    "def flatten_layer(x):\n",
    "    \n",
    "    size = x.get_shape()[1:4].num_elements()\n",
    "    out = tf.reshape(x, [-1,size])\n",
    "    return out, size\n",
    "\n",
    "# relu\n",
    "relu = lambda x: tf.nn.relu(features=x)\n",
    "\n",
    "# softmax\n",
    "softmax = lambda x: tf.nn.softmax(logits=x)\n",
    "\n",
    "# sigmoid\n",
    "sigmoid = lambda x: tf.nn.sigmoid(x)\n",
    "\n",
    "# batch norm\n",
    "batch_norm = lambda x: tf.layers.batch_normalization(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23470b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define CNN\n",
    "def toy_model(x,show_dim = False):\n",
    "    \n",
    "    # Six convolutional layers with max pool and ReLU\n",
    "    \n",
    "        #shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "    def conv_block(x,in_channels,out_channels, show_dim = False, stride = 2, kernel_h=10,kernel_w =10,):\n",
    "        shape = [kernel_h,kernel_w,in_channels,out_channels]\n",
    "        x = conv_layer(x, shape,stride)\n",
    "        x = relu(x)\n",
    "        x = batch_norm(x)\n",
    "        x = max_pool(x, k=2)\n",
    "        if show_dim:\n",
    "            print(x.shape)\n",
    "        return x\n",
    "    \n",
    "    x = conv_block(x,3,16,show_dim)\n",
    "\n",
    "    x = conv_block(x,16,16,show_dim)\n",
    "        \n",
    "    x = conv_block(x,16,32,show_dim)\n",
    "        \n",
    "    #x = conv_block(x,32,32,show_dim)\n",
    "    \n",
    "    #x = conv_block(x,64,64,show_dim)\n",
    "\n",
    "    # flatten output and put through a fully connected layer\n",
    "    flat1, size1 = flatten_layer(x)\n",
    "    print(flat1.shape)\n",
    "    fc1 = fully_connected_layer(flat1, [size1, 64])\n",
    "    fc1 = relu(fc1)\n",
    "    if show_dim:\n",
    "        print(fc1.shape)\n",
    "\n",
    "    fc2 = fully_connected_layer(fc1, [64, 1])\n",
    "    if show_dim:\n",
    "        print(fc2.shape)\n",
    "\n",
    "    return fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8858647",
   "metadata": {},
   "source": [
    "# dont pad, larger kernel size, do reduce feature space and less comp expensive\n",
    "\n",
    "- with unbalanced training, change the loss such that the minority gets much more weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37a79a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def sharpen(p):\n",
    "#     T = 0.5\n",
    "#     pred = p**(1./T)/(p**(1./T) + (1.-p)**(1./T))\n",
    "#     return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49b8f703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 185, 248, 16)\n",
      "(?, 44, 60, 16)\n",
      "(?, 9, 13, 32)\n",
      "(?, 3744)\n",
      "(?, 64)\n",
      "(?, 1)\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# define inputs\n",
    "x = tf.placeholder(tf.float32, [None, v_dim, h_dim, 3])\n",
    "y = tf.placeholder(tf.float32, [None, 1])\n",
    "y_train_true = np.array(train_labels).reshape(-1,1)\n",
    "y_test_true = np.array(test_labels).reshape(-1,1)\n",
    "\n",
    "# run model with placeholder tensors\n",
    "pred = toy_model(x,show_dim = True)\n",
    "\n",
    "# sharpen\n",
    "# pred = sharpen(pred)\n",
    "\n",
    "# define loss\n",
    "cross_entropy = tf.losses.sigmoid_cross_entropy(logits=pred, multi_class_labels=y)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# define accuracy\n",
    "pred_class = tf.round(sigmoid(pred))\n",
    "pred_correct = tf.equal(pred_class, tf.cast(y, tf.float32))\n",
    "accuracy = tf.reduce_mean(tf.cast(pred_correct, tf.float32))\n",
    "\n",
    "# define optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cost)\n",
    "\n",
    "# initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "training_iters = 450\n",
    "batch_size = 16 #len(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c10a870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Loss= 0.525604, Training Accuracy= 0.74013 ,Testing Accuracy: 0.86420\n",
      "Iter 1, Loss= 1.278190, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 2, Loss= 0.809888, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 3, Loss= 0.419077, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 4, Loss= 0.682539, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 5, Loss= 0.377895, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 6, Loss= 0.417774, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 7, Loss= 0.415782, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 8, Loss= 0.416516, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 9, Loss= 0.408797, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 10, Loss= 0.408063, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 11, Loss= 0.408231, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 12, Loss= 0.407948, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 13, Loss= 0.407582, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 14, Loss= 0.407118, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 15, Loss= 0.407649, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 16, Loss= 0.406924, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 17, Loss= 0.406747, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 18, Loss= 0.406621, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 19, Loss= 0.406519, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 20, Loss= 0.406404, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 21, Loss= 0.406379, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 22, Loss= 0.406234, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 23, Loss= 0.406102, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 24, Loss= 0.406062, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 25, Loss= 0.405979, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 26, Loss= 0.405892, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 27, Loss= 0.405768, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 28, Loss= 0.405676, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 29, Loss= 0.403396, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 30, Loss= 0.409850, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 31, Loss= 0.408981, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 32, Loss= 0.406230, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 33, Loss= 0.383098, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 34, Loss= 0.499192, Training Accuracy= 0.87500 ,Testing Accuracy: 0.86420\n",
      "Iter 35, Loss= 0.404041, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 36, Loss= 0.406573, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 37, Loss= 0.406809, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 38, Loss= 0.406005, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 39, Loss= 0.405428, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 40, Loss= 0.405124, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 41, Loss= 0.404921, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 42, Loss= 0.404758, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 43, Loss= 0.404617, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 44, Loss= 0.404496, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 45, Loss= 0.404394, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 46, Loss= 0.404307, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 47, Loss= 0.404231, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 48, Loss= 0.404163, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 49, Loss= 0.404102, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 50, Loss= 0.399638, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 51, Loss= 0.416197, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 52, Loss= 0.406836, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 53, Loss= 0.404215, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 54, Loss= 0.404137, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 55, Loss= 0.404336, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 56, Loss= 0.404336, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 57, Loss= 0.404244, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 58, Loss= 0.404155, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 59, Loss= 0.404086, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 60, Loss= 0.404031, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 61, Loss= 0.403983, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 62, Loss= 0.403940, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 63, Loss= 0.403900, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 64, Loss= 0.403864, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 65, Loss= 0.403827, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 66, Loss= 0.403804, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 67, Loss= 0.403773, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 68, Loss= 0.403743, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 69, Loss= 0.403716, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 70, Loss= 0.403696, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 71, Loss= 0.403670, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 72, Loss= 0.403649, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 73, Loss= 0.403626, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 74, Loss= 0.403608, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 75, Loss= 0.403576, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 76, Loss= 0.403591, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 77, Loss= 0.403553, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 78, Loss= 0.403528, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 79, Loss= 0.403508, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 80, Loss= 0.403505, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 81, Loss= 0.403480, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 82, Loss= 0.403458, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 83, Loss= 0.403444, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 84, Loss= 0.403454, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 85, Loss= 0.403641, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 86, Loss= 0.403681, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 87, Loss= 0.403416, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 88, Loss= 0.403330, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 89, Loss= 0.403338, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 90, Loss= 0.403331, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 91, Loss= 0.403315, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 92, Loss= 0.403310, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 93, Loss= 0.403284, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 94, Loss= 0.403272, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 95, Loss= 0.403254, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 96, Loss= 0.403237, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 97, Loss= 0.403231, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 98, Loss= 0.403207, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 99, Loss= 0.403197, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 100, Loss= 0.403175, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 101, Loss= 0.403165, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 102, Loss= 0.403146, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 103, Loss= 0.403133, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 104, Loss= 0.403113, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 105, Loss= 0.403107, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 106, Loss= 0.403081, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 107, Loss= 0.403075, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 108, Loss= 0.403051, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 109, Loss= 0.403038, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 110, Loss= 0.403021, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 111, Loss= 0.403006, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 112, Loss= 0.402986, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 113, Loss= 0.402979, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 114, Loss= 0.402954, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 115, Loss= 0.402943, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 116, Loss= 0.402916, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 117, Loss= 0.402900, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 118, Loss= 0.403014, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 119, Loss= 0.403299, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 120, Loss= 0.403022, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 121, Loss= 0.402798, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 122, Loss= 0.402787, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 123, Loss= 0.402810, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 124, Loss= 0.402793, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 125, Loss= 0.402772, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 126, Loss= 0.402757, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 127, Loss= 0.402740, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 128, Loss= 0.402719, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 129, Loss= 0.402701, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 130, Loss= 0.402687, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 131, Loss= 0.402664, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 132, Loss= 0.402666, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 133, Loss= 0.402639, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 134, Loss= 0.402617, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 135, Loss= 0.402604, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 136, Loss= 0.402578, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 137, Loss= 0.402565, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 138, Loss= 0.402542, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 139, Loss= 0.402532, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 140, Loss= 0.402506, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 141, Loss= 0.402505, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 142, Loss= 0.402478, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 143, Loss= 0.402449, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 144, Loss= 0.402460, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 145, Loss= 0.402435, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 146, Loss= 0.402417, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 147, Loss= 0.402399, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 148, Loss= 0.402380, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 149, Loss= 0.402362, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 150, Loss= 0.402343, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 151, Loss= 0.402324, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 152, Loss= 0.402305, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 153, Loss= 0.402283, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 154, Loss= 0.402255, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 155, Loss= 0.402278, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 156, Loss= 0.402608, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 157, Loss= 0.402550, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 158, Loss= 0.402186, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 159, Loss= 0.402129, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 160, Loss= 0.402132, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 161, Loss= 0.402079, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 162, Loss= 0.402154, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 163, Loss= 0.402132, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 164, Loss= 0.402112, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 165, Loss= 0.402095, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 166, Loss= 0.402069, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 167, Loss= 0.402050, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 168, Loss= 0.402019, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 169, Loss= 0.402012, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 170, Loss= 0.401999, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 171, Loss= 0.401980, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 172, Loss= 0.401961, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 173, Loss= 0.401932, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 174, Loss= 0.401906, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 175, Loss= 0.401888, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 176, Loss= 0.401890, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 177, Loss= 0.401861, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 178, Loss= 0.401863, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 179, Loss= 0.401832, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 180, Loss= 0.401812, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 181, Loss= 0.401793, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 182, Loss= 0.401774, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 183, Loss= 0.401756, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 184, Loss= 0.401737, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 185, Loss= 0.401719, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 186, Loss= 0.401701, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 187, Loss= 0.401682, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 188, Loss= 0.401663, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 189, Loss= 0.401643, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 190, Loss= 0.401627, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 191, Loss= 0.401606, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 192, Loss= 0.401585, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 193, Loss= 0.401672, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 194, Loss= 0.401963, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 195, Loss= 0.401732, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 196, Loss= 0.401530, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 197, Loss= 0.401566, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 198, Loss= 0.401544, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 199, Loss= 0.401477, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 200, Loss= 0.401448, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 201, Loss= 0.401435, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 202, Loss= 0.401420, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 203, Loss= 0.401404, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 204, Loss= 0.401387, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 205, Loss= 0.401369, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 206, Loss= 0.401352, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 207, Loss= 0.401334, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 208, Loss= 0.401316, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 209, Loss= 0.401299, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 210, Loss= 0.401282, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 211, Loss= 0.401265, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 212, Loss= 0.401248, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 213, Loss= 0.401231, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 214, Loss= 0.401215, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 215, Loss= 0.401198, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 216, Loss= 0.401182, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 217, Loss= 0.401165, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 218, Loss= 0.401149, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 219, Loss= 0.401133, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 220, Loss= 0.401117, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 221, Loss= 0.401102, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 222, Loss= 0.401087, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 223, Loss= 0.401071, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 224, Loss= 0.401030, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 225, Loss= 0.401130, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 226, Loss= 0.401069, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 227, Loss= 0.401067, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 228, Loss= 0.401033, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 229, Loss= 0.401180, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 230, Loss= 0.401261, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 231, Loss= 0.401005, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 232, Loss= 0.400889, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 233, Loss= 0.400883, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 234, Loss= 0.400881, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 235, Loss= 0.400897, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 236, Loss= 0.401046, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 237, Loss= 0.401198, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 238, Loss= 0.401228, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 239, Loss= 0.400968, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 240, Loss= 0.400767, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 241, Loss= 0.400818, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 242, Loss= 0.400840, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 243, Loss= 0.400834, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 244, Loss= 0.400786, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 245, Loss= 0.400728, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 246, Loss= 0.400696, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 247, Loss= 0.400680, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 248, Loss= 0.400666, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 249, Loss= 0.400652, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 250, Loss= 0.400637, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 251, Loss= 0.400625, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 252, Loss= 0.400624, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 253, Loss= 0.400642, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 254, Loss= 0.400636, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 255, Loss= 0.400590, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 256, Loss= 0.400548, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 257, Loss= 0.400526, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 258, Loss= 0.400513, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 259, Loss= 0.400500, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 260, Loss= 0.400486, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 261, Loss= 0.400498, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 262, Loss= 0.400616, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 263, Loss= 0.400690, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 264, Loss= 0.400705, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 265, Loss= 0.400747, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 266, Loss= 0.400468, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 267, Loss= 0.400442, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 268, Loss= 0.400557, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 269, Loss= 0.400543, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 270, Loss= 0.400557, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 271, Loss= 0.400523, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 272, Loss= 0.400411, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 273, Loss= 0.400292, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 274, Loss= 0.400244, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 275, Loss= 0.400236, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 276, Loss= 0.400231, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 277, Loss= 0.400226, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 278, Loss= 0.400210, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 279, Loss= 0.400192, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 280, Loss= 0.400412, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 281, Loss= 0.400212, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 282, Loss= 0.400125, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 283, Loss= 0.400108, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 284, Loss= 0.400101, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 285, Loss= 0.400091, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 286, Loss= 0.400086, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 287, Loss= 0.400105, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 288, Loss= 0.400173, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 289, Loss= 0.400193, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 290, Loss= 0.400132, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 291, Loss= 0.400136, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 292, Loss= 0.400171, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 293, Loss= 0.400129, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 294, Loss= 0.400114, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 295, Loss= 0.400132, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 296, Loss= 0.400103, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 297, Loss= 0.400066, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 298, Loss= 0.400045, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 299, Loss= 0.399969, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 300, Loss= 0.399928, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 301, Loss= 0.399932, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 302, Loss= 0.399892, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 303, Loss= 0.399834, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 304, Loss= 0.399799, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 305, Loss= 0.399780, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 306, Loss= 0.399765, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 307, Loss= 0.399750, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 308, Loss= 0.399735, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 309, Loss= 0.399731, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 310, Loss= 0.399801, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 311, Loss= 0.399854, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 312, Loss= 0.399785, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 313, Loss= 0.399723, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 314, Loss= 0.399676, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 315, Loss= 0.399652, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 316, Loss= 0.399680, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 317, Loss= 0.399818, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 318, Loss= 0.399949, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 319, Loss= 0.399769, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 320, Loss= 0.399662, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 321, Loss= 0.399813, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 322, Loss= 0.399862, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 323, Loss= 0.399745, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 324, Loss= 0.399623, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 325, Loss= 0.399656, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 326, Loss= 0.399643, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 327, Loss= 0.399542, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 328, Loss= 0.399521, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 329, Loss= 0.399492, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 330, Loss= 0.399434, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 331, Loss= 0.399399, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 332, Loss= 0.399383, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 333, Loss= 0.399415, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 334, Loss= 0.399611, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 335, Loss= 0.399603, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 336, Loss= 0.399384, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 337, Loss= 0.399333, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 338, Loss= 0.399365, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 339, Loss= 0.399363, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 340, Loss= 0.399329, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 341, Loss= 0.399334, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 342, Loss= 0.399406, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 343, Loss= 0.399499, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 344, Loss= 0.399440, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 345, Loss= 0.399283, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 346, Loss= 0.399214, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 347, Loss= 0.399196, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 348, Loss= 0.399193, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 349, Loss= 0.399260, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 350, Loss= 0.399461, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 351, Loss= 0.399483, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 352, Loss= 0.399312, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 353, Loss= 0.399157, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 354, Loss= 0.399216, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 355, Loss= 0.399615, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 356, Loss= 0.399605, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 357, Loss= 0.399205, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 358, Loss= 0.399043, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 359, Loss= 0.399037, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 360, Loss= 0.399055, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 361, Loss= 0.399053, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 362, Loss= 0.399041, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 363, Loss= 0.399053, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 364, Loss= 0.399126, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 365, Loss= 0.399243, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 366, Loss= 0.399198, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 367, Loss= 0.399099, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 368, Loss= 0.399056, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 369, Loss= 0.399080, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 370, Loss= 0.399132, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 371, Loss= 0.399081, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 372, Loss= 0.399014, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 373, Loss= 0.398956, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 374, Loss= 0.398905, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 375, Loss= 0.398884, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 376, Loss= 0.398886, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 377, Loss= 0.398918, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 378, Loss= 0.398979, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 379, Loss= 0.399016, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 380, Loss= 0.399036, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 381, Loss= 0.398997, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 382, Loss= 0.398926, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 383, Loss= 0.398904, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 384, Loss= 0.398885, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 385, Loss= 0.398935, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 386, Loss= 0.398984, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 387, Loss= 0.398922, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 388, Loss= 0.398960, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 389, Loss= 0.398936, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 390, Loss= 0.398835, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 391, Loss= 0.398867, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 392, Loss= 0.398929, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 393, Loss= 0.398889, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 394, Loss= 0.398790, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 395, Loss= 0.398736, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 396, Loss= 0.398739, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 397, Loss= 0.398767, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 398, Loss= 0.398819, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 399, Loss= 0.398842, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 400, Loss= 0.398728, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 401, Loss= 0.398645, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 402, Loss= 0.398651, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 403, Loss= 0.398701, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 404, Loss= 0.398715, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 405, Loss= 0.398671, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 406, Loss= 0.398639, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 407, Loss= 0.398664, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 408, Loss= 0.398743, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 409, Loss= 0.398823, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 410, Loss= 0.398756, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 411, Loss= 0.398631, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 412, Loss= 0.398687, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 413, Loss= 0.398808, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 414, Loss= 0.398750, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 415, Loss= 0.398647, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 416, Loss= 0.398623, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 417, Loss= 0.398709, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 418, Loss= 0.398808, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 419, Loss= 0.398730, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 420, Loss= 0.398574, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 421, Loss= 0.398508, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 422, Loss= 0.398467, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 423, Loss= 0.398435, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 424, Loss= 0.398423, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 425, Loss= 0.398427, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 426, Loss= 0.398466, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 427, Loss= 0.398592, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 428, Loss= 0.398741, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 429, Loss= 0.398701, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 430, Loss= 0.398534, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 431, Loss= 0.398423, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 432, Loss= 0.398430, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 433, Loss= 0.398493, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 434, Loss= 0.398512, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 435, Loss= 0.398439, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 436, Loss= 0.398358, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 437, Loss= 0.398374, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 438, Loss= 0.398484, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 439, Loss= 0.398592, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 440, Loss= 0.398578, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n",
      "Iter 441, Loss= 0.398572, Training Accuracy= 0.86842 ,Testing Accuracy: 0.86420\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(init)\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    best_acc = 0.\n",
    "    summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
    "    num_batches = len(train_idx)//batch_size\n",
    "    \n",
    "    for i in range(training_iters):\n",
    "        \n",
    "        # Reset metrics\n",
    "        loss_total = 0\n",
    "        acc_total = 0\n",
    "        train_results = []\n",
    "   \n",
    "        # Run optimization \n",
    "        # Calculate batch loss and accuracy\n",
    "        for batch in range(num_batches):\n",
    "            batch_x = data_img[train_idx,:,:,:][batch*batch_size:min((batch+1)*batch_size,len(train_idx))]\n",
    "            batch_y = y_train_true[batch*batch_size:min((batch+1)*batch_size,len(y_train_true))]    \n",
    "\n",
    "            feed_dict={x: batch_x, y: batch_y}\n",
    "            opt = sess.run(optimizer, feed_dict=feed_dict)\n",
    "            loss, acc, pred_labels = sess.run([cost, accuracy, pred_class], feed_dict=feed_dict)\n",
    "            loss_total += loss\n",
    "            acc_total += acc\n",
    "            train_results.append(pred_labels)\n",
    "\n",
    "        # Average metrics\n",
    "        ave_loss = loss_total/num_batches\n",
    "        ave_acc = acc_total/num_batches\n",
    "\n",
    "        # Calculate accuracy for all test images\n",
    "        valid_loss, test_acc, test_results = sess.run([cost, accuracy, pred_class],\n",
    "                                feed_dict={x: data_img[test_idx,:,:,:], y : y_test_true})\n",
    "        \n",
    "        # Update metrics\n",
    "        train_loss.append(ave_loss)\n",
    "        test_loss.append(valid_loss)\n",
    "        train_accuracy.append(ave_acc)\n",
    "        test_accuracy.append(test_acc)\n",
    "        if test_acc > best_acc:\n",
    "            best_model_train_labels = tf.stack(tf.reshape(tf.stack(train_results),[-1,1])).eval()\n",
    "            best_model_test_labels = test_results\n",
    "            best_acc = test_acc\n",
    "        \n",
    "        # Print metrics\n",
    "        print(\"Iter \" + str(i) + \", Loss= \" + \\\n",
    "                      \"{:.6f}\".format(ave_loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.5f}\".format(ave_acc)+ \\\n",
    "                      \" ,Testing Accuracy:\",\"{:.5f}\".format(test_acc))\n",
    "    summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391a1ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a48e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278b614f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd16f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "for title, data in {\"Loss\":train_loss,\"Train Accuracy\": train_accuracy, \"Test Accuracy\": test_accuracy}.items():\n",
    "    plt.plot(data)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02592675",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p37)",
   "language": "python",
   "name": "conda_tensorflow_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
