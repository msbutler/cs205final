{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f07c8493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "987367f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7554149c",
   "metadata": {},
   "source": [
    "Should take around 3 minutes to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b807b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data from Memory\n",
      "Loaded!\n"
     ]
    }
   ],
   "source": [
    "h_dim = 1000\n",
    "v_dim = 750\n",
    "print(\"Loading Data from Memory\")\n",
    "\n",
    "root = \"Train\"\n",
    "label_flood_dir = os.path.join(root,'Labeled','Flooded','image')\n",
    "label_nonflood_dir = os.path.join(root,'Labeled','Non-Flooded','image')\n",
    "flooded_img = []\n",
    "nonflooded_img = []\n",
    "\n",
    "for file in os.listdir(label_flood_dir):\n",
    "    image = Image.open(os.path.join(label_flood_dir, file))\n",
    "    flooded_img.append(np.array(image.resize((h_dim,v_dim))))\n",
    "    \n",
    "for file in os.listdir(label_nonflood_dir):\n",
    "    image = Image.open(os.path.join(label_nonflood_dir, file))\n",
    "    nonflooded_img.append(np.array(image.resize((h_dim,v_dim))))\n",
    "print(\"Loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f26586fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flooded Image Shape: (750, 1000, 3)\n",
      "Non_Flooded Image Shape: (750, 1000, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(397, 750, 1000, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Flooded Image Shape: {}\".format(flooded_img[0].shape))\n",
    "print(\"Non_Flooded Image Shape: {}\".format(nonflooded_img[0].shape))\n",
    "\n",
    "data_img = np.vstack((np.array(flooded_img), np.array(nonflooded_img))) / 255.\n",
    "data_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3ee3dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Index: [  0   1   3   5   6   7   9  10  11  12  13  14  15  17  18  19  21  22\n",
      "  23  24  26  27  29  30  31  33  34  35  37  38  39  40  42  43  44  46\n",
      "  47  48  49  50  52  58  72  74  76  86  89  99 103 107 121 133 137 147\n",
      " 150 152 156 165 194 199 209 210 219 228 236 239 258 259 260 263 278 279\n",
      " 281 282 299 311 350 363 373 396]\n",
      "Testing Index: [  2   4   8  16  20  25  28  32  36  41  45  87 106 112 113 134 138 216\n",
      " 261 262 312 349]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "test = False\n",
    "\n",
    "#n is number images from each class (flooded or non flooded)\n",
    "if test == True:\n",
    "    n = 20\n",
    "    #train_idx = np.array([np.arange(7),np.arange(10,17)]).flatten()\n",
    "    #test_idx = np.array([np.arange(7,10),np.arange(17,20)]).flatten()\n",
    "else:\n",
    "    n = min(len(flooded_img),len(nonflooded_img))\n",
    "\n",
    "'''split data 50 50'''\n",
    "def train_test_split(n):\n",
    "    idxs = list(range(n))\n",
    "    s = int(np.floor(0.8*n)) # number of images for training\n",
    "    \n",
    "    train_idx = []\n",
    "    test_idx = []\n",
    "    \n",
    "    #index range to select from (flooded img range, non flooded image range)\n",
    "    for s_i,e_i in [(0,len(flooded_img)),(len(flooded_img),len(data_img))]:\n",
    "        \n",
    "        #print(s_i,e_i,n,s)\n",
    "        #get all poss indexes for set\n",
    "        s_idx = list(range(s_i,e_i))\n",
    "        random.shuffle(s_idx)\n",
    "        \n",
    "        train_idx.extend(s_idx[:s])      #first s images are for training\n",
    "        test_idx.extend(s_idx[s:n])      # next n-s images are for testing. \n",
    "        #print(len(train_idx))\n",
    "    \n",
    "    train_idx = np.array(train_idx)\n",
    "    test_idx = np.array(test_idx)\n",
    "    train_idx.sort()\n",
    "    test_idx.sort()\n",
    "    \n",
    "    train_labels = [1 if x<len(flooded_img) else 0 for x in train_idx]\n",
    "    test_labels = [1 if x<len(flooded_img) else 0 for x in test_idx]\n",
    "\n",
    "    print(\"Training Index: {}\".format(train_idx))\n",
    "    print(\"Testing Index: {}\".format(test_idx))\n",
    "    return train_idx, test_idx, train_labels, test_labels\n",
    "\n",
    "train_idx, test_idx, train_labels, test_labels = train_test_split(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f174344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutional layer\n",
    "# x the input \n",
    "# shape is dimension of input\n",
    "def conv_layer(x, shape):\n",
    "\n",
    "    weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "    bias = tf.Variable(tf.constant(0.05, shape=[shape[-1]]))\n",
    "\n",
    "    out = tf.nn.conv2d(input=x, filters=weights, strides=[1,1,1,1], padding='SAME')\n",
    "    out += bias\n",
    "    return out\n",
    "\n",
    "# pooling layer\n",
    "def max_pool(x, k=2):\n",
    "\n",
    "    out = tf.nn.max_pool(value=x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "    return out\n",
    "\n",
    "# fully connected layer\n",
    "def fully_connected_layer(x, shape):\n",
    "\n",
    "    weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "    bias = tf.Variable(tf.constant(0.05, shape=[shape[1]]))\n",
    "\n",
    "    out = tf.matmul(a=x, b=weights)\n",
    "    out += bias\n",
    "    return out\n",
    "\n",
    "# flatten layer\n",
    "def flatten_layer(x):\n",
    "    \n",
    "    size = x.get_shape()[1:4].num_elements()\n",
    "    out = tf.reshape(x, [-1,size])\n",
    "    return out, size\n",
    "\n",
    "# relu\n",
    "relu = lambda x: tf.nn.relu(features=x)\n",
    "\n",
    "# softmax\n",
    "softmax = lambda x: tf.nn.softmax(logits=x)\n",
    "\n",
    "# sigmoid\n",
    "sigmoid = lambda x: tf.nn.sigmoid(x)\n",
    "\n",
    "# batch norm\n",
    "batch_norm = lambda x: tf.layers.batch_normalization(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "23470b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define CNN\n",
    "def toy_model(x):\n",
    "    \n",
    "    # Six convolutional layers with max pool and ReLU\n",
    "    \n",
    "        #shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "    def conv_block(x,in_channels,out_channels,kernel_h=5,kernel_w =5):\n",
    "        shape = [kernel_h,kernel_w,in_channels,out_channels]\n",
    "        x = conv_layer(x, shape)\n",
    "        x = relu(x)\n",
    "        x = batch_norm(x)\n",
    "        x = max_pool(x, k=2)\n",
    "        return x\n",
    "    \n",
    "    x = conv_block(x,3,3)\n",
    "    x = conv_block(x,3,3)\n",
    "    x = conv_block(x,3,3)\n",
    "    x = conv_block(x,3,1)\n",
    "    x = conv_block(x,1,1)\n",
    "    x = conv_block(x,1,1)\n",
    "    \n",
    "#     shape0 = [5, 5, 3, 3]\n",
    "#     conv0 = conv_layer(x, shape0)\n",
    "#     conv0 = relu(conv0)\n",
    "#     conv0 = batch_norm(conv0)\n",
    "#     conv0 = max_pool(conv0, k=2)\n",
    "\n",
    "#     shape1 = [5, 5, 3, 3]\n",
    "#     conv1 = conv_layer(conv0, shape1)\n",
    "#     conv1 = relu(conv1)\n",
    "#     conv1 = batch_norm(conv1)\n",
    "#     conv1 = max_pool(conv1, k=2)\n",
    "\n",
    "#     shape2 = [5, 5, 3, 3]\n",
    "#     conv2 = conv_layer(conv1, shape2)\n",
    "#     conv2 = relu(conv2)\n",
    "#     conv2 = batch_norm(conv2)\n",
    "#     conv2 = max_pool(conv2, k=2)\n",
    "\n",
    "#     shape3 = [5, 5, 3, 1]\n",
    "#     conv3 = conv_layer(conv2, shape3)\n",
    "#     conv3 = relu(conv3)\n",
    "#     conv3 = batch_norm(conv3)\n",
    "#     conv3 = max_pool(conv3, k=2)\n",
    "\n",
    "#     shape4 = [5, 5, 1, 1]\n",
    "#     conv4 = conv_layer(conv3, shape4)\n",
    "#     conv4 = relu(conv4)\n",
    "#     conv4 = batch_norm(conv4)\n",
    "#     conv4 = max_pool(conv4, k=2)\n",
    "\n",
    "#     shape5 = [5, 5, 1, 1]\n",
    "#     conv5 = conv_layer(conv4, shape5)\n",
    "#     conv5 = relu(conv5)\n",
    "#     conv5 = batch_norm(conv5)\n",
    "#     conv5 = max_pool(conv5, k=2)\n",
    "\n",
    "    # flatten output and put through a fully connected layer\n",
    "    flat1, size1 = flatten_layer(conv5)\n",
    "    fc1 = fully_connected_layer(flat1, [size1, 64])\n",
    "    fc1 = relu(fc1)\n",
    "\n",
    "    fc2 = fully_connected_layer(fc1, [64, 1])\n",
    "\n",
    "    return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37a79a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sharpen(p):\n",
    "#     T = 0.5\n",
    "#     pred = p**(1./T)/(p**(1./T) + (1.-p)**(1./T))\n",
    "#     return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "49b8f703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define inputs\n",
    "x = tf.placeholder(tf.float32, [None, v_dim, h_dim, 3])\n",
    "y = tf.placeholder(tf.float32, [None, 1])\n",
    "y_train_true = np.array(train_labels).reshape(-1,1)\n",
    "y_test_true = np.array(test_labels).reshape(-1,1)\n",
    "\n",
    "# run model with placeholder tensors\n",
    "pred = toy_model(x)\n",
    "\n",
    "# sharpen\n",
    "# pred = sharpen(pred)\n",
    "\n",
    "# define loss\n",
    "cross_entropy = tf.losses.sigmoid_cross_entropy(logits=pred, multi_class_labels=y)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# define accuracy\n",
    "pred_class = tf.round(sigmoid(pred))\n",
    "pred_correct = tf.equal(pred_class, tf.cast(y, tf.float32))\n",
    "accuracy = tf.reduce_mean(tf.cast(pred_correct, tf.float32))\n",
    "\n",
    "# define optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cost)\n",
    "\n",
    "# initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "training_iters = 450\n",
    "batch_size = 20 #len(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4c10a870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Loss= 0.696784, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 1, Loss= 0.694490, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 2, Loss= 0.693930, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 3, Loss= 0.693698, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 4, Loss= 0.693570, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 5, Loss= 0.693490, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 6, Loss= 0.693438, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 7, Loss= 0.693404, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 8, Loss= 0.693380, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 9, Loss= 0.693364, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 10, Loss= 0.693353, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 11, Loss= 0.693354, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 12, Loss= 0.693348, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 13, Loss= 0.693356, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 14, Loss= 0.693338, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 15, Loss= 0.693326, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 16, Loss= 0.693317, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 17, Loss= 0.693312, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 18, Loss= 0.693301, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 19, Loss= 0.693298, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 20, Loss= 0.693294, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 21, Loss= 0.693293, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 22, Loss= 0.693280, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 23, Loss= 0.693274, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 24, Loss= 0.693271, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 25, Loss= 0.693269, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 26, Loss= 0.693265, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 27, Loss= 0.693263, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 28, Loss= 0.693261, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 29, Loss= 0.693259, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 30, Loss= 0.693257, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 31, Loss= 0.693175, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 32, Loss= 0.693191, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 33, Loss= 0.693204, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 34, Loss= 0.693212, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 35, Loss= 0.693216, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 36, Loss= 0.693216, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 37, Loss= 0.693215, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 38, Loss= 0.693213, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 39, Loss= 0.693209, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 40, Loss= 0.693206, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 41, Loss= 0.693203, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 42, Loss= 0.693200, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 43, Loss= 0.693197, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 44, Loss= 0.693194, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 45, Loss= 0.693191, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 46, Loss= 0.693188, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 47, Loss= 0.693186, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 48, Loss= 0.693184, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 49, Loss= 0.693181, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 50, Loss= 0.693179, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 51, Loss= 0.693177, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 52, Loss= 0.693175, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 53, Loss= 0.693173, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 54, Loss= 0.693171, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 55, Loss= 0.693169, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 56, Loss= 0.693167, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 57, Loss= 0.693165, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 58, Loss= 0.693164, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 59, Loss= 0.693162, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 60, Loss= 0.693161, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 61, Loss= 0.693159, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 62, Loss= 0.693158, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 63, Loss= 0.693156, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 64, Loss= 0.693155, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 65, Loss= 0.693154, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 66, Loss= 0.693152, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 67, Loss= 0.693151, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 68, Loss= 0.693150, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 69, Loss= 0.693149, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 70, Loss= 0.693148, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 71, Loss= 0.693147, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 72, Loss= 0.693146, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 73, Loss= 0.693145, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 74, Loss= 0.693144, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 75, Loss= 0.693143, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 76, Loss= 0.693142, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 77, Loss= 0.693141, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 78, Loss= 0.693140, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 79, Loss= 0.693139, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 80, Loss= 0.693139, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 81, Loss= 0.693138, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 82, Loss= 0.693137, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 83, Loss= 0.693136, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 84, Loss= 0.693136, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 85, Loss= 0.693135, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 86, Loss= 0.693134, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 87, Loss= 0.693133, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 88, Loss= 0.693133, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 89, Loss= 0.693132, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 90, Loss= 0.693131, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 91, Loss= 0.693130, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 92, Loss= 0.693130, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 93, Loss= 0.693129, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 94, Loss= 0.693128, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 95, Loss= 0.693128, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 96, Loss= 0.693127, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 97, Loss= 0.693126, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 98, Loss= 0.693125, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 99, Loss= 0.693124, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 100, Loss= 0.693124, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 101, Loss= 0.693123, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 102, Loss= 0.693122, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 103, Loss= 0.693122, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 104, Loss= 0.693120, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 105, Loss= 0.693119, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 106, Loss= 0.693119, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 107, Loss= 0.693116, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 108, Loss= 0.693116, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 109, Loss= 0.693115, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 110, Loss= 0.693112, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 111, Loss= 0.693110, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 112, Loss= 0.693109, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 113, Loss= 0.693106, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 114, Loss= 0.693103, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 115, Loss= 0.693100, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 116, Loss= 0.693096, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 117, Loss= 0.693092, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 118, Loss= 0.693087, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 119, Loss= 0.693081, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 120, Loss= 0.693072, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 121, Loss= 0.693064, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 122, Loss= 0.693052, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 123, Loss= 0.693031, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 124, Loss= 0.693004, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 125, Loss= 0.692980, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 126, Loss= 0.692941, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 127, Loss= 0.692897, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 128, Loss= 0.692839, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 129, Loss= 0.692765, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 130, Loss= 0.692656, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 131, Loss= 0.692463, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 132, Loss= 0.692233, Training Accuracy= 0.50000 ,Testing Accuracy: 0.50000\n",
      "Iter 133, Loss= 0.691964, Training Accuracy= 0.52500 ,Testing Accuracy: 0.50000\n",
      "Iter 134, Loss= 0.691064, Training Accuracy= 0.63750 ,Testing Accuracy: 0.59091\n",
      "Iter 135, Loss= 0.689621, Training Accuracy= 0.68750 ,Testing Accuracy: 0.63636\n",
      "Iter 136, Loss= 0.688234, Training Accuracy= 0.71250 ,Testing Accuracy: 0.63636\n",
      "Iter 137, Loss= 0.684981, Training Accuracy= 0.75000 ,Testing Accuracy: 0.72727\n",
      "Iter 138, Loss= 0.681438, Training Accuracy= 0.73750 ,Testing Accuracy: 0.77273\n",
      "Iter 139, Loss= 0.675958, Training Accuracy= 0.73750 ,Testing Accuracy: 0.68182\n",
      "Iter 140, Loss= 0.667310, Training Accuracy= 0.77500 ,Testing Accuracy: 0.77273\n",
      "Iter 141, Loss= 0.657680, Training Accuracy= 0.76250 ,Testing Accuracy: 0.77273\n",
      "Iter 142, Loss= 0.649130, Training Accuracy= 0.76250 ,Testing Accuracy: 0.77273\n",
      "Iter 143, Loss= 0.638108, Training Accuracy= 0.76250 ,Testing Accuracy: 0.77273\n",
      "Iter 144, Loss= 0.623091, Training Accuracy= 0.78750 ,Testing Accuracy: 0.77273\n",
      "Iter 145, Loss= 0.608695, Training Accuracy= 0.78750 ,Testing Accuracy: 0.77273\n",
      "Iter 146, Loss= 0.588312, Training Accuracy= 0.78750 ,Testing Accuracy: 0.77273\n",
      "Iter 147, Loss= 0.567632, Training Accuracy= 0.78750 ,Testing Accuracy: 0.77273\n",
      "Iter 148, Loss= 0.545084, Training Accuracy= 0.78750 ,Testing Accuracy: 0.77273\n",
      "Iter 149, Loss= 0.519494, Training Accuracy= 0.77500 ,Testing Accuracy: 0.77273\n",
      "Iter 150, Loss= 0.499515, Training Accuracy= 0.78750 ,Testing Accuracy: 0.77273\n",
      "Iter 151, Loss= 0.476500, Training Accuracy= 0.80000 ,Testing Accuracy: 0.77273\n",
      "Iter 152, Loss= 0.462112, Training Accuracy= 0.78750 ,Testing Accuracy: 0.77273\n",
      "Iter 153, Loss= 0.449265, Training Accuracy= 0.78750 ,Testing Accuracy: 0.77273\n",
      "Iter 154, Loss= 0.440340, Training Accuracy= 0.80000 ,Testing Accuracy: 0.77273\n",
      "Iter 155, Loss= 0.429338, Training Accuracy= 0.78750 ,Testing Accuracy: 0.77273\n",
      "Iter 156, Loss= 0.427134, Training Accuracy= 0.80000 ,Testing Accuracy: 0.77273\n",
      "Iter 157, Loss= 0.416474, Training Accuracy= 0.81250 ,Testing Accuracy: 0.77273\n",
      "Iter 158, Loss= 0.415347, Training Accuracy= 0.81250 ,Testing Accuracy: 0.77273\n",
      "Iter 159, Loss= 0.411260, Training Accuracy= 0.81250 ,Testing Accuracy: 0.77273\n",
      "Iter 160, Loss= 0.404097, Training Accuracy= 0.82500 ,Testing Accuracy: 0.77273\n",
      "Iter 161, Loss= 0.401129, Training Accuracy= 0.82500 ,Testing Accuracy: 0.77273\n",
      "Iter 162, Loss= 0.397975, Training Accuracy= 0.82500 ,Testing Accuracy: 0.77273\n",
      "Iter 163, Loss= 0.394282, Training Accuracy= 0.82500 ,Testing Accuracy: 0.77273\n",
      "Iter 164, Loss= 0.391626, Training Accuracy= 0.82500 ,Testing Accuracy: 0.77273\n",
      "Iter 165, Loss= 0.386359, Training Accuracy= 0.83750 ,Testing Accuracy: 0.77273\n",
      "Iter 166, Loss= 0.385527, Training Accuracy= 0.83750 ,Testing Accuracy: 0.77273\n",
      "Iter 167, Loss= 0.380422, Training Accuracy= 0.83750 ,Testing Accuracy: 0.77273\n",
      "Iter 168, Loss= 0.376403, Training Accuracy= 0.83750 ,Testing Accuracy: 0.77273\n",
      "Iter 169, Loss= 0.376838, Training Accuracy= 0.85000 ,Testing Accuracy: 0.77273\n",
      "Iter 170, Loss= 0.369708, Training Accuracy= 0.85000 ,Testing Accuracy: 0.77273\n",
      "Iter 171, Loss= 0.369644, Training Accuracy= 0.85000 ,Testing Accuracy: 0.77273\n",
      "Iter 172, Loss= 0.365071, Training Accuracy= 0.85000 ,Testing Accuracy: 0.77273\n",
      "Iter 173, Loss= 0.363062, Training Accuracy= 0.85000 ,Testing Accuracy: 0.77273\n",
      "Iter 174, Loss= 0.359886, Training Accuracy= 0.85000 ,Testing Accuracy: 0.77273\n",
      "Iter 175, Loss= 0.356900, Training Accuracy= 0.85000 ,Testing Accuracy: 0.77273\n",
      "Iter 176, Loss= 0.354143, Training Accuracy= 0.85000 ,Testing Accuracy: 0.77273\n",
      "Iter 177, Loss= 0.350129, Training Accuracy= 0.85000 ,Testing Accuracy: 0.77273\n",
      "Iter 178, Loss= 0.347520, Training Accuracy= 0.85000 ,Testing Accuracy: 0.77273\n",
      "Iter 179, Loss= 0.343692, Training Accuracy= 0.85000 ,Testing Accuracy: 0.77273\n",
      "Iter 180, Loss= 0.341096, Training Accuracy= 0.85000 ,Testing Accuracy: 0.77273\n",
      "Iter 181, Loss= 0.335772, Training Accuracy= 0.85000 ,Testing Accuracy: 0.77273\n",
      "Iter 182, Loss= 0.334965, Training Accuracy= 0.85000 ,Testing Accuracy: 0.77273\n",
      "Iter 183, Loss= 0.327774, Training Accuracy= 0.85000 ,Testing Accuracy: 0.77273\n",
      "Iter 184, Loss= 0.328916, Training Accuracy= 0.85000 ,Testing Accuracy: 0.77273\n",
      "Iter 185, Loss= 0.320939, Training Accuracy= 0.85000 ,Testing Accuracy: 0.77273\n",
      "Iter 186, Loss= 0.315755, Training Accuracy= 0.85000 ,Testing Accuracy: 0.77273\n",
      "Iter 187, Loss= 0.317299, Training Accuracy= 0.85000 ,Testing Accuracy: 0.77273\n",
      "Iter 188, Loss= 0.309159, Training Accuracy= 0.85000 ,Testing Accuracy: 0.77273\n",
      "Iter 189, Loss= 0.300668, Training Accuracy= 0.85000 ,Testing Accuracy: 0.77273\n",
      "Iter 190, Loss= 0.305167, Training Accuracy= 0.85000 ,Testing Accuracy: 0.77273\n",
      "Iter 191, Loss= 0.296663, Training Accuracy= 0.85000 ,Testing Accuracy: 0.77273\n",
      "Iter 192, Loss= 0.286681, Training Accuracy= 0.85000 ,Testing Accuracy: 0.77273\n",
      "Iter 193, Loss= 0.288018, Training Accuracy= 0.85000 ,Testing Accuracy: 0.77273\n",
      "Iter 194, Loss= 0.282785, Training Accuracy= 0.86250 ,Testing Accuracy: 0.77273\n",
      "Iter 195, Loss= 0.274017, Training Accuracy= 0.86250 ,Testing Accuracy: 0.77273\n",
      "Iter 196, Loss= 0.274817, Training Accuracy= 0.86250 ,Testing Accuracy: 0.77273\n",
      "Iter 197, Loss= 0.268249, Training Accuracy= 0.86250 ,Testing Accuracy: 0.77273\n",
      "Iter 198, Loss= 0.262877, Training Accuracy= 0.86250 ,Testing Accuracy: 0.77273\n",
      "Iter 199, Loss= 0.260565, Training Accuracy= 0.86250 ,Testing Accuracy: 0.77273\n",
      "Iter 200, Loss= 0.256767, Training Accuracy= 0.86250 ,Testing Accuracy: 0.77273\n",
      "Iter 201, Loss= 0.251945, Training Accuracy= 0.86250 ,Testing Accuracy: 0.77273\n",
      "Iter 202, Loss= 0.248196, Training Accuracy= 0.86250 ,Testing Accuracy: 0.77273\n",
      "Iter 203, Loss= 0.244910, Training Accuracy= 0.86250 ,Testing Accuracy: 0.77273\n",
      "Iter 204, Loss= 0.240496, Training Accuracy= 0.86250 ,Testing Accuracy: 0.77273\n",
      "Iter 205, Loss= 0.237246, Training Accuracy= 0.86250 ,Testing Accuracy: 0.77273\n",
      "Iter 206, Loss= 0.233791, Training Accuracy= 0.86250 ,Testing Accuracy: 0.77273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 207, Loss= 0.230240, Training Accuracy= 0.86250 ,Testing Accuracy: 0.77273\n",
      "Iter 208, Loss= 0.227473, Training Accuracy= 0.86250 ,Testing Accuracy: 0.77273\n",
      "Iter 209, Loss= 0.224264, Training Accuracy= 0.86250 ,Testing Accuracy: 0.77273\n",
      "Iter 210, Loss= 0.220807, Training Accuracy= 0.86250 ,Testing Accuracy: 0.77273\n",
      "Iter 211, Loss= 0.219024, Training Accuracy= 0.86250 ,Testing Accuracy: 0.77273\n",
      "Iter 212, Loss= 0.214755, Training Accuracy= 0.86250 ,Testing Accuracy: 0.77273\n",
      "Iter 213, Loss= 0.215842, Training Accuracy= 0.86250 ,Testing Accuracy: 0.77273\n",
      "Iter 214, Loss= 0.209714, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 215, Loss= 0.215198, Training Accuracy= 0.86250 ,Testing Accuracy: 0.77273\n",
      "Iter 216, Loss= 0.210184, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 217, Loss= 0.205889, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 218, Loss= 0.208102, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 219, Loss= 0.195996, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 220, Loss= 0.197262, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 221, Loss= 0.193325, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 222, Loss= 0.190651, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 223, Loss= 0.188479, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 224, Loss= 0.184539, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 225, Loss= 0.183239, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 226, Loss= 0.179784, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 227, Loss= 0.181409, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 228, Loss= 0.175435, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 229, Loss= 0.183842, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 230, Loss= 0.174618, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 231, Loss= 0.177292, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 232, Loss= 0.175491, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 233, Loss= 0.171645, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 234, Loss= 0.170493, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 235, Loss= 0.162832, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 236, Loss= 0.164261, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 237, Loss= 0.160237, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 238, Loss= 0.158966, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 239, Loss= 0.157986, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 240, Loss= 0.153651, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 241, Loss= 0.156878, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 242, Loss= 0.152767, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 243, Loss= 0.150817, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 244, Loss= 0.150307, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 245, Loss= 0.147136, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 246, Loss= 0.155887, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 247, Loss= 0.146070, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 248, Loss= 0.183869, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 249, Loss= 0.263007, Training Accuracy= 0.82500 ,Testing Accuracy: 0.77273\n",
      "Iter 250, Loss= 0.160530, Training Accuracy= 0.88750 ,Testing Accuracy: 0.77273\n",
      "Iter 251, Loss= 0.208216, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 252, Loss= 0.165686, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 253, Loss= 0.167059, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 254, Loss= 0.152863, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 255, Loss= 0.146589, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 256, Loss= 0.147530, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 257, Loss= 0.143438, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 258, Loss= 0.137386, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 259, Loss= 0.146198, Training Accuracy= 0.88750 ,Testing Accuracy: 0.77273\n",
      "Iter 260, Loss= 0.152540, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 261, Loss= 0.138647, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 262, Loss= 0.150250, Training Accuracy= 0.88750 ,Testing Accuracy: 0.77273\n",
      "Iter 263, Loss= 0.158682, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 264, Loss= 0.137846, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 265, Loss= 0.129927, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 266, Loss= 0.129056, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 267, Loss= 0.128246, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 268, Loss= 0.125986, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 269, Loss= 0.123531, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 270, Loss= 0.123183, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 271, Loss= 0.122121, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 272, Loss= 0.120941, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 273, Loss= 0.119920, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 274, Loss= 0.119252, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 275, Loss= 0.118107, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 276, Loss= 0.116943, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 277, Loss= 0.116179, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 278, Loss= 0.115274, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 279, Loss= 0.114337, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 280, Loss= 0.113729, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 281, Loss= 0.113152, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 282, Loss= 0.112088, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 283, Loss= 0.111426, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 284, Loss= 0.110605, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 285, Loss= 0.110988, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 286, Loss= 0.110181, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 287, Loss= 0.109311, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 288, Loss= 0.109258, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 289, Loss= 0.109320, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 290, Loss= 0.108102, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 291, Loss= 0.107080, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 292, Loss= 0.106399, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 293, Loss= 0.106016, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 294, Loss= 0.105333, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 295, Loss= 0.105452, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 296, Loss= 0.105242, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 297, Loss= 0.104743, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 298, Loss= 0.104160, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 299, Loss= 0.103691, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 300, Loss= 0.103374, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 301, Loss= 0.102949, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 302, Loss= 0.102443, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 303, Loss= 0.101936, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 304, Loss= 0.101810, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 305, Loss= 0.101581, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 306, Loss= 0.101195, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 307, Loss= 0.101266, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 308, Loss= 0.101143, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 309, Loss= 0.100732, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 310, Loss= 0.100256, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 311, Loss= 0.100093, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 312, Loss= 0.099642, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 313, Loss= 0.099217, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 314, Loss= 0.098996, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 315, Loss= 0.098816, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 316, Loss= 0.098487, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 317, Loss= 0.098617, Training Accuracy= 0.87500 ,Testing Accuracy: 0.77273\n",
      "Iter 318, Loss= 0.098672, Training Accuracy= 0.93750 ,Testing Accuracy: 0.77273\n",
      "Iter 319, Loss= 0.098372, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 320, Loss= 0.097927, Training Accuracy= 0.98750 ,Testing Accuracy: 0.81818\n",
      "Iter 321, Loss= 0.097741, Training Accuracy= 0.97500 ,Testing Accuracy: 0.81818\n",
      "Iter 322, Loss= 0.097428, Training Accuracy= 0.98750 ,Testing Accuracy: 0.77273\n",
      "Iter 323, Loss= 0.097009, Training Accuracy= 0.97500 ,Testing Accuracy: 0.77273\n",
      "Iter 324, Loss= 0.096693, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 325, Loss= 0.096529, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 326, Loss= 0.096354, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 327, Loss= 0.096082, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 328, Loss= 0.095824, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 329, Loss= 0.095643, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 330, Loss= 0.095535, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 331, Loss= 0.095250, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 332, Loss= 0.095076, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 333, Loss= 0.094946, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 334, Loss= 0.094736, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 335, Loss= 0.094492, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 336, Loss= 0.094367, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 337, Loss= 0.094173, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 338, Loss= 0.093920, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 339, Loss= 0.093690, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 340, Loss= 0.093447, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 341, Loss= 0.093274, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 342, Loss= 0.093111, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 343, Loss= 0.093375, Training Accuracy= 0.98750 ,Testing Accuracy: 0.77273\n",
      "Iter 344, Loss= 0.093352, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 345, Loss= 0.093894, Training Accuracy= 0.98750 ,Testing Accuracy: 0.81818\n",
      "Iter 346, Loss= 0.094754, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 347, Loss= 0.093930, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 348, Loss= 0.093625, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 349, Loss= 0.092888, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 350, Loss= 0.092223, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 351, Loss= 0.091961, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 352, Loss= 0.091770, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 353, Loss= 0.091461, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 354, Loss= 0.091289, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 355, Loss= 0.091172, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 356, Loss= 0.091024, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 357, Loss= 0.090897, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 358, Loss= 0.090725, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 359, Loss= 0.090545, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 360, Loss= 0.090345, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 361, Loss= 0.090157, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 362, Loss= 0.089959, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 363, Loss= 0.089802, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 364, Loss= 0.089634, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 365, Loss= 0.089457, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 366, Loss= 0.089331, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 367, Loss= 0.089213, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 368, Loss= 0.089041, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 369, Loss= 0.088919, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 370, Loss= 0.088769, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 371, Loss= 0.088648, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 372, Loss= 0.088512, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 373, Loss= 0.088381, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 374, Loss= 0.088250, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 375, Loss= 0.088108, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 376, Loss= 0.087970, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 377, Loss= 0.087837, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 378, Loss= 0.087773, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 379, Loss= 0.087643, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 380, Loss= 0.087568, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 381, Loss= 0.087560, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 382, Loss= 0.087399, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 383, Loss= 0.087266, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 384, Loss= 0.087139, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 385, Loss= 0.087011, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 386, Loss= 0.086901, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 387, Loss= 0.086776, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 388, Loss= 0.086646, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 389, Loss= 0.086536, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 390, Loss= 0.086449, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 391, Loss= 0.086344, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 392, Loss= 0.086239, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 393, Loss= 0.086131, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 394, Loss= 0.086008, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 395, Loss= 0.085927, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 396, Loss= 0.085815, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 397, Loss= 0.085801, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 398, Loss= 0.085788, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 399, Loss= 0.085661, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 400, Loss= 0.085550, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 401, Loss= 0.085635, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 402, Loss= 0.085510, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 403, Loss= 0.085308, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 404, Loss= 0.085170, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 405, Loss= 0.085034, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 406, Loss= 0.084910, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 407, Loss= 0.084831, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 408, Loss= 0.084727, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 409, Loss= 0.084622, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 410, Loss= 0.084514, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 411, Loss= 0.084402, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 412, Loss= 0.084323, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 413, Loss= 0.084236, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 414, Loss= 0.084138, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 415, Loss= 0.084055, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 416, Loss= 0.084004, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 417, Loss= 0.083902, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 418, Loss= 0.083812, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 419, Loss= 0.083761, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 420, Loss= 0.083670, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 421, Loss= 0.083585, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 422, Loss= 0.083498, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 423, Loss= 0.083404, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 424, Loss= 0.083314, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 425, Loss= 0.083219, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 426, Loss= 0.083126, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 427, Loss= 0.083082, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 428, Loss= 0.083032, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 429, Loss= 0.082931, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 430, Loss= 0.082826, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 431, Loss= 0.082756, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 432, Loss= 0.082690, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 433, Loss= 0.082599, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 434, Loss= 0.082494, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 435, Loss= 0.082409, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 436, Loss= 0.082338, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 437, Loss= 0.082273, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 438, Loss= 0.082269, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 439, Loss= 0.082233, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n",
      "Iter 440, Loss= 0.082645, Training Accuracy= 1.00000 ,Testing Accuracy: 0.81818\n",
      "Iter 441, Loss= 0.082784, Training Accuracy= 1.00000 ,Testing Accuracy: 0.77273\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-28b3f3d30e58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_class\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mloss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train model\n",
    "with tf.Session(config=config) as sess:\n",
    "    sess.run(init)\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    best_acc = 0.\n",
    "    summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
    "    num_batches = len(train_idx)//batch_size\n",
    "    \n",
    "    for i in range(training_iters):\n",
    "        \n",
    "        # Reset metrics\n",
    "        loss_total = 0\n",
    "        acc_total = 0\n",
    "        train_results = []\n",
    "   \n",
    "        # Run optimization \n",
    "        # Calculate batch loss and accuracy\n",
    "        for batch in range(num_batches):\n",
    "            batch_x = data_img[train_idx,:,:,:][batch*batch_size:min((batch+1)*batch_size,len(train_idx))]\n",
    "            batch_y = y_train_true[batch*batch_size:min((batch+1)*batch_size,len(y_train_true))]    \n",
    "\n",
    "            feed_dict={x: batch_x, y: batch_y}\n",
    "            opt = sess.run(optimizer, feed_dict=feed_dict)\n",
    "            loss, acc, pred_labels = sess.run([cost, accuracy, pred_class], feed_dict=feed_dict)\n",
    "            loss_total += loss\n",
    "            acc_total += acc\n",
    "            train_results.append(pred_labels)\n",
    "\n",
    "        # Average metrics\n",
    "        ave_loss = loss_total/num_batches\n",
    "        ave_acc = acc_total/num_batches\n",
    "\n",
    "        # Calculate accuracy for all test images\n",
    "        valid_loss, test_acc, test_results = sess.run([cost, accuracy, pred_class],\n",
    "                                feed_dict={x: data_img[test_idx,:,:,:], y : y_test_true})\n",
    "        \n",
    "        # Update metrics\n",
    "        train_loss.append(ave_loss)\n",
    "        test_loss.append(valid_loss)\n",
    "        train_accuracy.append(ave_acc)\n",
    "        test_accuracy.append(test_acc)\n",
    "        if test_acc > best_acc:\n",
    "            best_model_train_labels = tf.stack(tf.reshape(tf.stack(train_results),[-1,1])).eval()\n",
    "            best_model_test_labels = test_results\n",
    "            best_acc = test_acc\n",
    "        \n",
    "        # Print metrics\n",
    "        print(\"Iter \" + str(i) + \", Loss= \" + \\\n",
    "                      \"{:.6f}\".format(ave_loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.5f}\".format(ave_acc)+ \\\n",
    "                      \" ,Testing Accuracy:\",\"{:.5f}\".format(test_acc))\n",
    "    summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "391a1ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d1a48e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278b614f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8dd16f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for title, data in {\"Loss\":train_loss,\"Train Accuracy\": train_accuracy, \"Test Accuracy\": test_accuracy}.items():\n",
    "    plt.plot(data)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02592675",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p37)",
   "language": "python",
   "name": "conda_tensorflow_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
