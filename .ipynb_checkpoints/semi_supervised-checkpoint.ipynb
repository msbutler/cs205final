{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48a005d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p37/gpu_cuda10.0/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import numpy as np\n",
    "import skimage as sk\n",
    "from skimage import transform\n",
    "import random\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4588473c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([1.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0831f1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_img(image):\n",
    "    random_degree = random.uniform(-25, 25) #25% from left or right\n",
    "    return sk.transform.rotate(image, random_degree)\n",
    "\n",
    "def noise_img(image):\n",
    "    return sk.util.random_noise(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40b7ce11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 11696077419702454665)\n",
      "_DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 906144085598411061)\n",
      "_DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184, 8033130994100639172)\n",
      "_DeviceAttributes(/job:localhost/replica:0/task:0/device:GPU:0, GPU, 7518981325, 3788132736179045365)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    devices = sess.list_devices()\n",
    "    for d in devices:\n",
    "        print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41435162",
   "metadata": {},
   "outputs": [],
   "source": [
    "flooded_img = []\n",
    "nonflooded_img = []\n",
    "unlabeled_img = []\n",
    "\n",
    "h_dim  = 1000\n",
    "v_dim = 750\n",
    "\n",
    "root = \"Train\"\n",
    "flood_dir = os.path.join(root,'Labeled/Flooded/image/')\n",
    "nonflood_dir = os.path.join(root,'Labeled/Non-Flooded/image/')\n",
    "unlabel_dir = os.path.join(root,'Unlabeled/image/')\n",
    "\n",
    "for file in os.listdir(flood_dir):\n",
    "    image = Image.open(os.path.join(flood_dir, file))\n",
    "    image = np.array(image.resize((h_dim,v_dim)))\n",
    "    flooded_img.append(rotate_img(image))\n",
    "\n",
    "for file in os.listdir(nonflood_dir):\n",
    "    image = Image.open(os.path.join(nonflood_dir, file))\n",
    "    image = np.array(image.resize((h_dim,v_dim)))\n",
    "    nonflooded_img.append(rotate_img(image))\n",
    "    \n",
    "for file in os.listdir(unlabel_dir):\n",
    "    image = Image.open(os.path.join(unlabel_dir, file))\n",
    "    image = np.array(image.resize((h_dim,v_dim)))\n",
    "    unlabeled_img.append(rotate_img(image))\n",
    "    unlabeled_img.append(rotate_img(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e382be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flooded Image Shape: (750, 1000, 3)\n",
      "Non_Flooded Image Shape: (750, 1000, 3)\n",
      "Unlabeled Image Shape: (750, 1000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Flooded Image Shape: {}\".format(flooded_img[0].shape))\n",
    "print(\"Non_Flooded Image Shape: {}\".format(nonflooded_img[0].shape))\n",
    "print(\"Unlabeled Image Shape: {}\".format(unlabeled_img[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b04eb62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(397, 750, 1000, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_img = np.vstack((np.array(flooded_img), np.array(nonflooded_img))) / 255.\n",
    "data_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "240ede82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(366, 750, 1000, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_img = np.array(unlabeled_img) /255.\n",
    "unlabeled_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ed22dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Index: [  0   1   2   3   4   5   6   7   9  11  12  13  14  15  16  18  19  20\n",
      "  21  22  23  24  26  27  28  30  31  33  35  36  38  39  41  42  43  45\n",
      "  47  48  49  50  54  86 127 138 143 145 155 168 171 177 180 186 187 188\n",
      " 189 191 199 206 216 221 223 260 265 282 294 295 303 305 306 309 316 324\n",
      " 327 329 331 342 373 385 388 394]\n",
      "Testing Index: [  8  10  17  25  29  32  34  37  40  44  46 102 159 170 257 277 333 356\n",
      " 360 364 366 390]\n"
     ]
    }
   ],
   "source": [
    "#train_idx = np.array([np.arange(7),np.arange(10,17)]).flatten()\n",
    "#test_idx = np.array([np.arange(7,10),np.arange(17,20)]).flatten()\n",
    "\n",
    "test = False\n",
    "\n",
    "#n is number images from each class (flooded or non flooded)\n",
    "if test == True:\n",
    "    n = 20\n",
    "else:\n",
    "    n = min(len(flooded_img),len(nonflooded_img))\n",
    "\n",
    "\n",
    "def train_test_split(n,unlabelled=None):\n",
    "    idxs = list(range(n))\n",
    "    s = int(np.floor(0.8*n)) # number of images for training\n",
    "    \n",
    "    train_idx = []\n",
    "    test_idx = []\n",
    "    \n",
    "    #index range to select from (flooded img range, non flooded image range)\n",
    "    for s_i,e_i in [(0,len(flooded_img)),(len(flooded_img),len(data_img))]:\n",
    "        \n",
    "        #print(s_i,e_i,n,s)\n",
    "        #get all poss indexes for set\n",
    "        s_idx = list(range(s_i,e_i))\n",
    "        random.shuffle(s_idx)\n",
    "        \n",
    "        train_idx.extend(s_idx[:s])      #first s images are for training\n",
    "        test_idx.extend(s_idx[s:n])      # next n-s images are for testing. \n",
    "        #print(len(train_idx))\n",
    "    \n",
    "    train_idx = np.array(train_idx)\n",
    "    test_idx = np.array(test_idx)\n",
    "    train_idx.sort()\n",
    "    test_idx.sort()\n",
    "    \n",
    "    train_labels = [1 if x<len(flooded_img) else 0 for x in train_idx]\n",
    "    test_labels = [1 if x<len(flooded_img) else 0 for x in test_idx]\n",
    "\n",
    "    print(\"Training Index: {}\".format(train_idx))\n",
    "    print(\"Testing Index: {}\".format(test_idx))\n",
    "    return train_idx, test_idx, train_labels, test_labels\n",
    "\n",
    "train_idx, test_idx, train_labels, test_labels = train_test_split(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2353f5b",
   "metadata": {},
   "source": [
    "### CNN CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43414411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutional layer\n",
    "def conv_layer(x, shape):\n",
    "\n",
    "    weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "    bias = tf.Variable(tf.constant(0.05, shape=[shape[-1]]))\n",
    "\n",
    "    out = tf.nn.conv2d(input=x, filters=weights, strides=[1,1,1,1], padding='SAME')\n",
    "    out += bias\n",
    "    return out\n",
    "\n",
    "# pooling layer\n",
    "def max_pool(x, k=2):\n",
    "\n",
    "    out = tf.nn.max_pool(value=x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "    return out\n",
    "\n",
    "# fully connected layer\n",
    "def fully_connected_layer(x, shape):\n",
    "\n",
    "    weights = tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "    bias = tf.Variable(tf.constant(0.05, shape=[shape[1]]))\n",
    "\n",
    "    out = tf.matmul(a=x, b=weights)\n",
    "    out += bias\n",
    "    return out\n",
    "\n",
    "# flatten layer\n",
    "def flatten_layer(x):\n",
    "    \n",
    "    size = x.get_shape()[1:4].num_elements()\n",
    "    out = tf.reshape(x, [-1,size])\n",
    "    return out, size\n",
    "\n",
    "# relu\n",
    "relu = lambda x: tf.nn.relu(features=x)\n",
    "\n",
    "# softmax\n",
    "softmax = lambda x: tf.nn.softmax(logits=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55f05da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "# define CNN\n",
    "def toy_model(x):\n",
    "\n",
    "    # three convolutional layers with max pool\n",
    "    shape0 = [5, 5, 3, 3]\n",
    "    conv0 = conv_layer(x, shape0)\n",
    "    conv0 = max_pool(conv0, k=2)\n",
    "\n",
    "    shape1 = [5, 5, 3, 1]\n",
    "    conv1 = conv_layer(conv0, shape1)\n",
    "    conv1 = max_pool(conv1, k=2)\n",
    "\n",
    "    shape2 = [5, 5, 1, 1]\n",
    "    conv2 = conv_layer(conv1, shape2)\n",
    "    conv2 = max_pool(conv2, k=2)\n",
    "\n",
    "    # flatten output and put through a fully connected layer\n",
    "    flat1, size1 = flatten_layer(conv2)\n",
    "    fc1 = fully_connected_layer(flat1, [size1, 64])\n",
    "    fc1 = relu(fc1)\n",
    "\n",
    "    fc2 = fully_connected_layer(fc1, [64, 1])\n",
    "    out = softmax(fc2)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63b33c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_guess_label(pred_u_raw, k):\n",
    "    # guess label = average prediction over k augmentations of same image\n",
    "    # num_images = pred_u_raw.shape[0].value / k # Throws error of NoneType and int since pred_u_raw.shape[0].value is None\n",
    "    \n",
    "    try:\n",
    "        num_images = int(pred_u_raw.shape[0].value / k)\n",
    "\n",
    "        idx = 0\n",
    "        temp_labels = []\n",
    "        for i in range(num_images):\n",
    "            temp_labels.append(tf.reduce_mean(pred_u_raw[idx:idx+k]))\n",
    "            idx += k\n",
    "\n",
    "        # repeat label for each augmentation\n",
    "        guess_labels = tf.repeat(tf.stack(temp_labels), k)\n",
    "\n",
    "        # reshape and remove gradient tracking\n",
    "        guess_labels = tf.reshape(guess_labels, (-1,1))\n",
    "        guess_labels = tf.stop_gradient(guess_labels)\n",
    "\n",
    "        return guess_labels\n",
    "\n",
    "    except TypeError:\n",
    "      \n",
    "      return pred_u_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5896de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define inputs\n",
    "hdim = data_img[0].shape[0]\n",
    "vdim = data_img[0].shape[1]\n",
    "x = tf.placeholder(tf.float32, [None, hdim, vdim, 3]) # labeled images (augmented)\n",
    "u = tf.placeholder(tf.float32, [None, hdim, vdim, 3]) # unlabeled images (augmented)\n",
    "y = tf.placeholder(tf.float32, [None, 1]) # labels\n",
    "y_train_true = np.array(train_labels).reshape(-1,1)\n",
    "y_test_true = np.array(test_labels).reshape(-1,1)\n",
    "k = 2 # augment images k times\n",
    "\n",
    "# Google paper section 3.5 says 100 is a good place to start for w_unlabeled\n",
    "# Google paper also suggests ramping up value to 100 over first 16,000 epochs\n",
    "w_unlabeled = 100. \n",
    "\n",
    "# run model with placeholder tensors\n",
    "pred_x = toy_model(x)\n",
    "pred_u_raw = toy_model(u)\n",
    "\n",
    "# calculate guess labels for unlabeled images \n",
    "pred_u = generate_guess_label(pred_u_raw, k)\n",
    "\n",
    "# sharpen guess labels here? is this necessary for only 2 classes?\n",
    "\n",
    "# define loss\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=pred_x, labels=y)\n",
    "labeled_loss = tf.reduce_mean(cross_entropy)\n",
    "unlabeled_loss = tf.nn.l2_loss(pred_u - pred_u_raw)\n",
    "cost = labeled_loss + w_unlabeled*unlabeled_loss\n",
    "\n",
    "# define accuracy\n",
    "pred_correct = tf.equal(tf.argmax(pred_x, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(pred_correct, tf.float32))\n",
    "\n",
    "# define optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "\n",
    "# initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "training_iters = 3\n",
    "batch_size = 4 #len(train_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59391378",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "abb58683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Loss= 0.000000, Training Accuracy= 1.00000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_labeled_idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-aa001c0a68d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Calculate accuracy for all test images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         test_acc,valid_loss = sess.run([accuracy,cost],\n\u001b[0;32m---> 41\u001b[0;31m                                 feed_dict={x: data_img[test_labeled_idx,:,:,:], u: data_img[test_unlabeled_idx,:,:,:], y : y_test_true})\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mave_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_labeled_idx' is not defined"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
    "    num_batches = len(train_idx)//batch_size\n",
    "\n",
    "    \n",
    "    for i in range(training_iters):\n",
    "        \n",
    "        # Reset metrics\n",
    "        loss_total = 0\n",
    "        acc_total = 0\n",
    "   \n",
    "        # Run optimization \n",
    "        # Calculate batch loss and accuracy\n",
    "        for batch in range(num_batches):\n",
    "            batch_x = data_img[train_idx,:,:,:][batch*batch_size:min((batch+1)*batch_size, len(train_idx))]\n",
    "            batch_u = unlabeled_img[:,:,:,:][batch*k*batch_size:min((batch+1)*k*batch_size, unlabeled_img.shape[0])]\n",
    "            batch_y = y_train_true[batch*batch_size:min((batch+1)*batch_size, len(y_train_true))]   \n",
    "\n",
    "            feed_dict={x: batch_x, u: batch_u, y: batch_y}\n",
    "            opt = sess.run(optimizer, feed_dict=feed_dict)\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict=feed_dict)\n",
    "            loss_total += loss\n",
    "            acc_total += acc\n",
    "\n",
    "        # Average metrics\n",
    "        ave_loss = loss_total/num_batches\n",
    "        ave_acc = acc_total/num_batches\n",
    "\n",
    "        print(\"Iter \" + str(i) + \", Loss= \" + \\\n",
    "                      \"{:.6f}\".format(ave_loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.5f}\".format(ave_acc))\n",
    "\n",
    "        # Calculate accuracy for all test images\n",
    "        test_acc,valid_loss = sess.run([accuracy,cost],\n",
    "                                feed_dict={x: data_img[test_labeled_idx,:,:,:], u: data_img[test_unlabeled_idx,:,:,:], y : y_test_true})\n",
    "        train_loss.append(ave_loss)\n",
    "        test_loss.append(valid_loss)\n",
    "        train_accuracy.append(ave_acc)\n",
    "        test_accuracy.append(test_acc)\n",
    "        print(\"Testing Accuracy:\",\"{:.5f}\".format(test_acc))\n",
    "    summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8779ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p37)",
   "language": "python",
   "name": "conda_tensorflow_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
